{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import apiquery\n",
    "import pandas as pd\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "DATA_PATH = '../01.Data'\n",
    "shutil.copy(\"apiquery_pyc.py\", \"apiquery.pyc\")\n",
    "module_path = \"../src\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from utils.training import *\n",
    "from utils.encoding import *\n",
    "from utils.utils import *\n",
    "from models.models import Roberta_Model\n",
    "from dataset.dataset import BNPParibasText\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "pd.set_option('display.max_rows', 900)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(data_loader, model, device):\n",
    "    from tqdm.notebook import tqdm\n",
    "    # Put the model in eval mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    # List for store final predictions\n",
    "    final_predictions = []\n",
    "    with torch.no_grad():\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "        for b_idx, data in enumerate(tk0):\n",
    "            for key,value in data.items():\n",
    "                data[key] = value.to(device)\n",
    "            predictions = model._embeddings(data['ids'],data['mask'])\n",
    "            predictions = predictions.cpu()\n",
    "            final_predictions.append(predictions)\n",
    "    return np.vstack(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH   = 16\n",
    "PRETRAINED   = 'roberta-base'\n",
    "SEED         = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.26 s, sys: 217 ms, total: 2.48 s\n",
      "Wall time: 2.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train     = pd.read_csv(os.path.join(\"../01.Data\",'fold.csv'))\n",
    "y_submission = pd.read_csv(os.path.join(DATA_PATH,'y_test_submission_example.tsv'), index_col='Index', encoding='utf-8', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0cfdb527904c4e8e19e946ce9c1832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3189.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 19s, sys: 12.4 s, total: 1min 31s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "COLUMN_NAME  = 'product_name' \n",
    "tokenizer     = transformers.RobertaTokenizer.from_pretrained(PRETRAINED)\n",
    "train_dataset = BNPParibasText(df_train,MAX_LENGTH,tokenizer,COLUMN_NAME)\n",
    "model         = Roberta_Model(pretrained_model=PRETRAINED)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size  = 32,\n",
    "        pin_memory  = True,\n",
    "        num_workers = 72\n",
    "    )\n",
    "emb_sentence_train = get_embedding(train_loader, model, 'cuda')\n",
    "df_train[[f'emb_{COLUMN_NAME}_{i}' for i in range(emb_sentence_train.shape[1])]] = emb_sentence_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLUMN_NAME  = 'ingredients_text' \n",
    "#tokenizer     = transformers.RobertaTokenizer.from_pretrained(PRETRAINED)\n",
    "#train_dataset = BNPParibasText(df_train,MAX_LENGTH,tokenizer,COLUMN_NAME)\n",
    "#model         = Roberta_Model(pretrained_model=PRETRAINED)\n",
    "#train_loader = torch.utils.data.DataLoader(\n",
    "#        train_dataset,\n",
    "#        batch_size  = 32,\n",
    "#        pin_memory  = True,\n",
    "#        num_workers = 72\n",
    "#    )\n",
    "#emb_sentence_train = get_embedding(train_loader, model, 'cuda')\n",
    "#df_train[[f'emb_{COLUMN_NAME}_{i}' for i in range(emb_sentence_train.shape[1])]] = emb_sentence_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['states_en_brands', 'states_en_categories', 'states_en_characteristics', 'states_en_expiration date', 'states_en_general_complete', 'states_en_ingredients', 'pnns_groups_1', 'pnns_groups_2', 'states_en_packaging', 'states_en_packaging-code-', 'states_en_photo_upload', 'states_en_photo_validate', 'states_en_product name', 'states_en_quantity']\n"
     ]
    }
   ],
   "source": [
    "columns_modeling = ['additives_n','ingredients_from_palm_oil_n',\n",
    "                    'ingredients_that_may_be_from_palm_oil_n','target',\n",
    "                    'states_en_brands','states_en_categories','states_en_characteristics','states_en_expiration date',\n",
    "                    'states_en_general_complete','states_en_ingredients','pnns_groups_1','pnns_groups_2',\n",
    "                    'states_en_packaging','states_en_packaging-code-','states_en_photo_upload',\n",
    "                    'states_en_photo_validate','states_en_product name','states_en_quantity','diff_t'] + [f'emb_{i}' for i in range(emb_sentence_train.shape[1])]\n",
    "columns_label = df_train[columns_modeling].select_dtypes(include=['object']).columns.to_list()\n",
    "print(columns_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: Missing as new category\n",
      "Label Encoding:  label_states_en_brands\n",
      "Label Encoding:  label_states_en_categories\n",
      "Label Encoding:  label_states_en_characteristics\n",
      "Label Encoding:  label_states_en_expiration date\n",
      "Label Encoding:  label_states_en_general_complete\n",
      "Label Encoding:  label_states_en_ingredients\n",
      "Label Encoding:  label_pnns_groups_1\n",
      "Label Encoding:  label_pnns_groups_2\n",
      "Label Encoding:  label_states_en_packaging\n",
      "Label Encoding:  label_states_en_packaging-code-\n",
      "Label Encoding:  label_states_en_photo_upload\n",
      "Label Encoding:  label_states_en_photo_validate\n",
      "Label Encoding:  label_states_en_product name\n",
      "Label Encoding:  label_states_en_quantity\n"
     ]
    }
   ],
   "source": [
    "df_train,dict_le = label_encoding(df_train,label_cols = columns_label, drop_original = True, missing_new_cat = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'rmse'},\n",
    "        'num_leaves':10,\n",
    "        'learning_rate': 0.1,\n",
    "        \"min_child_samples\": 150,\n",
    "        \"max_depth\" : 5,\n",
    "        'feature_fraction':  0.7,\n",
    "        \"bagging_freq\": 1,\n",
    "        'bagging_fraction': 0.75,\n",
    "        \"is_unbalance\" : False,\n",
    "        'force_col_wise':True,\n",
    "        'num_threads':18,\n",
    "        #\"scale_pos_weight\":5 -> Generally  is the ratio of number of negative class to the positive class.\n",
    "        'bagging_seed':42,\n",
    "        'lambda_l1':1.5,\n",
    "        'lambda_l2':1,\n",
    "        'verbose': 1\n",
    "\n",
    "}\n",
    "cat_columns = [i for i in df_train.columns.to_list() if i.startswith('label_')]\n",
    "columns_modeling_last = list(set(columns_modeling)-set(columns_label)) + ['fold'] + cat_columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['emb_714', 'emb_432', 'emb_139', 'emb_587', 'emb_306', 'emb_321', 'emb_433', 'emb_45', 'emb_511', 'emb_168', 'emb_156', 'emb_177', 'emb_151', 'emb_600', 'emb_162', 'emb_295', 'emb_318', 'emb_326', 'emb_249', 'emb_583', 'emb_328', 'emb_29', 'emb_649', 'emb_665', 'emb_69', 'emb_580', 'emb_598', 'emb_495', 'emb_647', 'emb_554', 'emb_485', 'emb_541', 'emb_348', 'emb_675', 'emb_264', 'emb_193', 'emb_115', 'emb_64', 'diff_t', 'emb_288', 'emb_72', 'emb_155', 'emb_585', 'emb_59', 'emb_100', 'emb_97', 'emb_722', 'emb_88', 'emb_104', 'emb_559', 'emb_3', 'emb_429', 'emb_142', 'emb_407', 'emb_467', 'emb_451', 'emb_682', 'emb_522', 'emb_292', 'emb_458', 'emb_687', 'emb_444', 'emb_691', 'emb_514', 'emb_277', 'emb_323', 'emb_693', 'emb_241', 'emb_255', 'emb_91', 'emb_362', 'emb_82', 'emb_297', 'emb_259', 'emb_582', 'emb_99', 'emb_285', 'emb_570', 'emb_41', 'emb_105', 'emb_409', 'emb_445', 'emb_534', 'emb_110', 'emb_557', 'emb_388', 'emb_669', 'emb_590', 'emb_305', 'emb_86', 'emb_159', 'emb_525', 'emb_55', 'emb_50', 'emb_172', 'emb_279', 'emb_335', 'emb_133', 'emb_480', 'emb_537', 'emb_761', 'emb_767', 'emb_468', 'emb_494', 'emb_185', 'emb_401', 'emb_196', 'emb_353', 'emb_147', 'emb_561', 'emb_28', 'emb_596', 'emb_642', 'emb_599', 'emb_273', 'emb_271', 'emb_204', 'emb_607', 'emb_686', 'emb_616', 'emb_322', 'emb_230', 'emb_32', 'emb_556', 'emb_571', 'emb_361', 'emb_472', 'emb_276', 'emb_80', 'emb_446', 'emb_613', 'emb_762', 'emb_73', 'emb_562', 'emb_512', 'emb_548', 'emb_754', 'emb_194', 'emb_203', 'emb_332', 'emb_360', 'emb_415', 'emb_449', 'emb_560', 'emb_725', 'emb_157', 'emb_357', 'emb_400', 'emb_78', 'emb_572', 'emb_720', 'emb_688', 'emb_152', 'emb_439', 'emb_431', 'emb_57', 'emb_174', 'emb_158', 'emb_132', 'emb_66', 'emb_421', 'emb_763', 'emb_533', 'emb_459', 'emb_315', 'emb_12', 'emb_207', 'emb_317', 'emb_694', 'emb_56', 'emb_27', 'emb_68', 'emb_236', 'emb_130', 'emb_486', 'emb_527', 'emb_447', 'emb_251', 'emb_394', 'emb_452', 'emb_161', 'emb_503', 'emb_709', 'emb_416', 'emb_617', 'emb_681', 'emb_87', 'emb_742', 'emb_54', 'emb_414', 'emb_77', 'emb_146', 'emb_330', 'emb_635', 'emb_626', 'emb_84', 'emb_46', 'emb_354', 'emb_736', 'emb_118', 'emb_650', 'emb_532', 'emb_113', 'emb_475', 'emb_111', 'emb_364', 'emb_597', 'emb_622', 'emb_419', 'emb_717', 'emb_378', 'emb_192', 'emb_180', 'emb_555', 'emb_536', 'emb_623', 'emb_610', 'emb_413', 'emb_540', 'emb_674', 'emb_282', 'emb_643', 'emb_49', 'emb_748', 'emb_589', 'emb_187', 'emb_405', 'emb_499', 'emb_520', 'emb_44', 'emb_186', 'emb_546', 'emb_320', 'emb_746', 'emb_417', 'emb_201', 'emb_181', 'emb_516', 'emb_487', 'emb_558', 'emb_462', 'emb_191', 'emb_43', 'emb_202', 'emb_379', 'emb_76', 'emb_695', 'emb_275', 'emb_428', 'emb_165', 'emb_52', 'emb_23', 'emb_741', 'emb_237', 'emb_531', 'emb_175', 'emb_493', 'emb_471', 'emb_263', 'emb_550', 'emb_641', 'emb_340', 'emb_74', 'emb_344', 'emb_545', 'emb_2', 'emb_655', 'emb_257', 'emb_621', 'emb_327', 'emb_129', 'emb_718', 'emb_539', 'emb_666', 'emb_603', 'emb_112', 'emb_689', 'emb_606', 'emb_258', 'emb_301', 'emb_406', 'emb_604', 'emb_198', 'emb_591', 'emb_667', 'emb_355', 'emb_210', 'emb_140', 'emb_40', 'emb_373', 'emb_171', 'emb_309', 'emb_465', 'emb_543', 'emb_579', 'emb_584', 'emb_602', 'emb_544', 'emb_31', 'emb_569', 'emb_628', 'emb_424', 'emb_497', 'emb_437', 'emb_36', 'emb_254', 'emb_169', 'emb_154', 'emb_656', 'emb_338', 'emb_103', 'emb_398', 'emb_94', 'emb_566', 'emb_116', 'emb_238', 'emb_538', 'emb_753', 'emb_586', 'emb_34', 'emb_299', 'emb_9', 'emb_120', 'emb_712', 'emb_477', 'emb_303', 'emb_261', 'emb_455', 'emb_269', 'emb_163', 'emb_510', 'emb_418', 'emb_713', 'emb_500', 'emb_719', 'emb_744', 'ingredients_that_may_be_from_palm_oil_n', 'emb_611', 'emb_233', 'emb_408', 'emb_508', 'emb_731', 'emb_244', 'emb_221', 'emb_574', 'emb_102', 'emb_359', 'emb_95', 'emb_456', 'emb_425', 'emb_266', 'emb_294', 'emb_213', 'emb_399', 'emb_26', 'ingredients_from_palm_oil_n', 'emb_38', 'emb_716', 'emb_126', 'emb_206', 'emb_96', 'emb_135', 'emb_60', 'emb_235', 'emb_690', 'emb_33', 'emb_482', 'emb_392', 'emb_197', 'emb_345', 'emb_470', 'emb_247', 'emb_481', 'emb_4', 'emb_170', 'emb_15', 'emb_551', 'emb_123', 'emb_179', 'emb_624', 'emb_680', 'emb_128', 'emb_658', 'emb_250', 'emb_594', 'emb_521', 'emb_92', 'emb_483', 'emb_324', 'emb_149', 'emb_685', 'emb_200', 'emb_18', 'emb_389', 'emb_648', 'emb_612', 'emb_199', 'emb_374', 'emb_220', 'emb_625', 'emb_670', 'emb_751', 'emb_268', 'emb_308', 'emb_496', 'emb_387', 'emb_371', 'emb_339', 'emb_509', 'emb_438', 'emb_58', 'emb_61', 'emb_98', 'emb_565', 'emb_668', 'emb_404', 'emb_676', 'emb_307', 'emb_274', 'emb_764', 'emb_765', 'emb_37', 'emb_283', 'emb_83', 'emb_661', 'emb_747', 'emb_476', 'emb_316', 'emb_578', 'emb_11', 'emb_724', 'emb_402', 'emb_646', 'emb_260', 'emb_121', 'emb_298', 'emb_253', 'emb_410', 'emb_653', 'emb_239', 'emb_601', 'emb_662', 'emb_701', 'emb_153', 'emb_107', 'emb_85', 'emb_160', 'emb_517', 'emb_302', 'emb_632', 'emb_350', 'emb_188', 'emb_265', 'emb_311', 'emb_334', 'emb_51', 'emb_705', 'emb_683', 'emb_563', 'emb_535', 'emb_383', 'emb_217', 'emb_434', 'emb_526', 'emb_502', 'emb_501', 'emb_491', 'emb_138', 'emb_397', 'emb_310', 'emb_728', 'emb_234', 'emb_492', 'emb_20', 'emb_479', 'emb_367', 'emb_79', 'emb_524', 'emb_281', 'emb_341', 'emb_403', 'emb_6', 'emb_270', 'emb_141', 'emb_342', 'emb_506', 'emb_678', 'emb_654', 'emb_42', 'emb_343', 'emb_53', 'emb_750', 'emb_457', 'emb_638', 'emb_507', 'emb_150', 'emb_664', 'emb_660', 'emb_365', 'emb_393', 'emb_166', 'emb_289', 'emb_395', 'emb_730', 'emb_347', 'emb_464', 'emb_125', 'emb_707', 'emb_697', 'emb_376', 'emb_759', 'emb_290', 'emb_216', 'emb_671', 'emb_24', 'emb_618', 'emb_119', 'emb_35', 'emb_651', 'emb_14', 'emb_679', 'emb_659', 'emb_745', 'emb_48', 'emb_518', 'emb_450', 'emb_21', 'emb_93', 'emb_757', 'emb_463', 'emb_240', 'emb_164', 'emb_319', 'emb_325', 'emb_699', 'emb_605', 'emb_0', 'emb_22', 'emb_351', 'emb_183', 'emb_243', 'emb_256', 'emb_313', 'emb_189', 'emb_489', 'emb_564', 'emb_644', 'emb_528', 'emb_304', 'emb_692', 'emb_633', 'emb_443', 'emb_368', 'additives_n', 'emb_608', 'emb_504', 'emb_749', 'emb_229', 'emb_65', 'emb_331', 'emb_286', 'emb_702', 'emb_677', 'emb_453', 'emb_287', 'emb_71', 'emb_127', 'emb_90', 'emb_755', 'emb_176', 'emb_214', 'emb_639', 'emb_756', 'emb_484', 'emb_490', 'emb_114', 'emb_549', 'emb_454', 'emb_391', 'emb_637', 'emb_67', 'emb_291', 'emb_228', 'emb_478', 'emb_513', 'emb_629', 'emb_333', 'emb_346', 'emb_377', 'emb_440', 'emb_634', 'emb_684', 'emb_25', 'emb_735', 'emb_708', 'emb_696', 'emb_766', 'emb_101', 'emb_529', 'emb_16', 'emb_498', 'emb_734', 'emb_620', 'emb_448', 'emb_715', 'emb_381', 'emb_743', 'emb_252', 'emb_108', 'emb_293', 'emb_427', 'emb_136', 'emb_614', 'emb_473', 'emb_208', 'emb_469', 'emb_219', 'emb_117', 'emb_173', 'emb_519', 'emb_337', 'emb_356', 'emb_657', 'emb_627', 'emb_1', 'emb_222', 'emb_272', 'emb_706', 'emb_442', 'emb_144', 'emb_758', 'emb_225', 'emb_435', 'emb_384', 'emb_673', 'emb_411', 'emb_738', 'emb_593', 'emb_215', 'emb_218', 'emb_420', 'emb_430', 'emb_576', 'emb_205', 'emb_703', 'emb_62', 'emb_227', 'emb_167', 'emb_212', 'emb_134', 'emb_575', 'emb_145', 'emb_39', 'emb_231', 'emb_312', 'emb_567', 'emb_143', 'emb_314', 'emb_542', 'emb_573', 'emb_436', 'emb_547', 'emb_422', 'emb_733', 'emb_248', 'emb_737', 'emb_466', 'emb_278', 'emb_426', 'emb_137', 'emb_592', 'emb_386', 'emb_284', 'emb_246', 'emb_523', 'emb_8', 'emb_710', 'emb_122', 'emb_5', 'emb_296', 'emb_396', 'emb_17', 'emb_267', 'emb_505', 'emb_7', 'emb_698', 'emb_385', 'emb_19', 'emb_672', 'emb_636', 'emb_148', 'emb_577', 'emb_723', 'emb_652', 'emb_595', 'emb_369', 'emb_124', 'emb_640', 'emb_630', 'emb_47', 'emb_721', 'emb_375', 'emb_700', 'emb_224', 'emb_358', 'emb_349', 'emb_581', 'emb_530', 'emb_280', 'emb_631', 'emb_740', 'emb_10', 'emb_382', 'emb_232', 'emb_75', 'emb_195', 'emb_732', 'emb_619', 'emb_226', 'emb_615', 'emb_81', 'emb_423', 'emb_663', 'emb_131', 'emb_461', 'emb_729', 'emb_209', 'emb_352', 'emb_262', 'emb_366', 'emb_727', 'emb_300', 'emb_711', 'emb_370', 'emb_515', 'emb_30', 'emb_363', 'emb_553', 'emb_441', 'emb_223', 'emb_739', 'emb_609', 'emb_726', 'emb_372', 'emb_390', 'emb_412', 'emb_645', 'emb_190', 'emb_63', 'emb_752', 'emb_178', 'emb_380', 'emb_106', 'emb_336', 'emb_760', 'emb_460', 'emb_329', 'emb_70', 'emb_588', 'emb_474', 'emb_704', 'emb_211', 'emb_568', 'emb_89', 'emb_184', 'emb_182', 'emb_109', 'emb_245', 'emb_552', 'emb_242', 'emb_13', 'emb_488', 'label_states_en_brands', 'label_states_en_categories', 'label_states_en_characteristics', 'label_states_en_expiration date', 'label_states_en_general_complete', 'label_states_en_ingredients', 'label_pnns_groups_1', 'label_pnns_groups_2', 'label_states_en_packaging', 'label_states_en_packaging-code-', 'label_states_en_photo_upload', 'label_states_en_photo_validate', 'label_states_en_product name', 'label_states_en_quantity']\n",
      "Cat index: [772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785]\n",
      "---------- Training fold NÂº 1 ----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 196221\n",
      "[LightGBM] [Info] Number of data points in the train set: 81622, number of used features: 786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.171473\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's rmse: 7.15048\tvalid_1's rmse: 7.19671\n",
      "[100]\ttraining's rmse: 6.829\tvalid_1's rmse: 6.91856\n",
      "[150]\ttraining's rmse: 6.6475\tvalid_1's rmse: 6.78574\n",
      "[200]\ttraining's rmse: 6.51129\tvalid_1's rmse: 6.69623\n",
      "[250]\ttraining's rmse: 6.39836\tvalid_1's rmse: 6.62652\n",
      "[300]\ttraining's rmse: 6.30048\tvalid_1's rmse: 6.57082\n",
      "[350]\ttraining's rmse: 6.21597\tvalid_1's rmse: 6.53202\n",
      "[400]\ttraining's rmse: 6.1356\tvalid_1's rmse: 6.49608\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[450]\ttraining's rmse: 6.06237\tvalid_1's rmse: 6.46456\n",
      "[500]\ttraining's rmse: 5.99195\tvalid_1's rmse: 6.43434\n",
      "[550]\ttraining's rmse: 5.92712\tvalid_1's rmse: 6.40972\n",
      "[600]\ttraining's rmse: 5.86328\tvalid_1's rmse: 6.38479\n",
      "[650]\ttraining's rmse: 5.80185\tvalid_1's rmse: 6.36345\n",
      "[700]\ttraining's rmse: 5.74489\tvalid_1's rmse: 6.34442\n",
      "[750]\ttraining's rmse: 5.68924\tvalid_1's rmse: 6.32766\n",
      "[800]\ttraining's rmse: 5.63713\tvalid_1's rmse: 6.31062\n",
      "[850]\ttraining's rmse: 5.58627\tvalid_1's rmse: 6.29748\n",
      "[900]\ttraining's rmse: 5.53713\tvalid_1's rmse: 6.28152\n",
      "[950]\ttraining's rmse: 5.48854\tvalid_1's rmse: 6.26985\n",
      "[1000]\ttraining's rmse: 5.44089\tvalid_1's rmse: 6.25684\n",
      "[1050]\ttraining's rmse: 5.39554\tvalid_1's rmse: 6.24489\n",
      "[1100]\ttraining's rmse: 5.35038\tvalid_1's rmse: 6.2354\n",
      "[1150]\ttraining's rmse: 5.30799\tvalid_1's rmse: 6.22549\n",
      "[1200]\ttraining's rmse: 5.26531\tvalid_1's rmse: 6.21492\n",
      "[1250]\ttraining's rmse: 5.22442\tvalid_1's rmse: 6.20636\n",
      "[1300]\ttraining's rmse: 5.18374\tvalid_1's rmse: 6.19832\n",
      "[1350]\ttraining's rmse: 5.14368\tvalid_1's rmse: 6.18898\n",
      "[1400]\ttraining's rmse: 5.10645\tvalid_1's rmse: 6.17973\n",
      "[1450]\ttraining's rmse: 5.06963\tvalid_1's rmse: 6.17188\n",
      "[1500]\ttraining's rmse: 5.03235\tvalid_1's rmse: 6.16335\n",
      "[1550]\ttraining's rmse: 4.99703\tvalid_1's rmse: 6.15679\n",
      "[1600]\ttraining's rmse: 4.96174\tvalid_1's rmse: 6.14971\n",
      "[1650]\ttraining's rmse: 4.92565\tvalid_1's rmse: 6.14183\n",
      "[1700]\ttraining's rmse: 4.89185\tvalid_1's rmse: 6.13567\n",
      "[1750]\ttraining's rmse: 4.85622\tvalid_1's rmse: 6.12669\n",
      "[1800]\ttraining's rmse: 4.82284\tvalid_1's rmse: 6.11875\n",
      "[1850]\ttraining's rmse: 4.79152\tvalid_1's rmse: 6.11376\n",
      "[1900]\ttraining's rmse: 4.75874\tvalid_1's rmse: 6.10489\n",
      "[1950]\ttraining's rmse: 4.72686\tvalid_1's rmse: 6.09868\n",
      "[2000]\ttraining's rmse: 4.69503\tvalid_1's rmse: 6.09245\n",
      "[2050]\ttraining's rmse: 4.66445\tvalid_1's rmse: 6.08716\n",
      "[2100]\ttraining's rmse: 4.63449\tvalid_1's rmse: 6.08267\n",
      "[2150]\ttraining's rmse: 4.60494\tvalid_1's rmse: 6.07851\n",
      "[2200]\ttraining's rmse: 4.57473\tvalid_1's rmse: 6.07444\n",
      "[2250]\ttraining's rmse: 4.54622\tvalid_1's rmse: 6.06927\n",
      "[2300]\ttraining's rmse: 4.51787\tvalid_1's rmse: 6.06369\n",
      "[2350]\ttraining's rmse: 4.49004\tvalid_1's rmse: 6.05868\n",
      "[2400]\ttraining's rmse: 4.46204\tvalid_1's rmse: 6.05381\n",
      "[2450]\ttraining's rmse: 4.43425\tvalid_1's rmse: 6.0499\n",
      "[2500]\ttraining's rmse: 4.40686\tvalid_1's rmse: 6.04493\n",
      "[2550]\ttraining's rmse: 4.37941\tvalid_1's rmse: 6.04145\n",
      "[2600]\ttraining's rmse: 4.35315\tvalid_1's rmse: 6.03783\n",
      "[2650]\ttraining's rmse: 4.32829\tvalid_1's rmse: 6.0349\n",
      "[2700]\ttraining's rmse: 4.30148\tvalid_1's rmse: 6.03022\n",
      "[2750]\ttraining's rmse: 4.27561\tvalid_1's rmse: 6.02819\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2800]\ttraining's rmse: 4.25079\tvalid_1's rmse: 6.0254\n",
      "[2850]\ttraining's rmse: 4.22688\tvalid_1's rmse: 6.02155\n",
      "[2900]\ttraining's rmse: 4.20262\tvalid_1's rmse: 6.01794\n",
      "[2950]\ttraining's rmse: 4.17859\tvalid_1's rmse: 6.01582\n",
      "[3000]\ttraining's rmse: 4.15482\tvalid_1's rmse: 6.01301\n",
      "[3050]\ttraining's rmse: 4.13168\tvalid_1's rmse: 6.01194\n",
      "[3100]\ttraining's rmse: 4.10756\tvalid_1's rmse: 6.00924\n",
      "[3150]\ttraining's rmse: 4.08488\tvalid_1's rmse: 6.0076\n",
      "[3200]\ttraining's rmse: 4.06239\tvalid_1's rmse: 6.00531\n",
      "[3250]\ttraining's rmse: 4.04007\tvalid_1's rmse: 6.00279\n",
      "[3300]\ttraining's rmse: 4.01761\tvalid_1's rmse: 6.00019\n",
      "[3350]\ttraining's rmse: 3.99542\tvalid_1's rmse: 5.99809\n",
      "[3400]\ttraining's rmse: 3.9729\tvalid_1's rmse: 5.99465\n",
      "[3450]\ttraining's rmse: 3.95138\tvalid_1's rmse: 5.9922\n",
      "[3500]\ttraining's rmse: 3.93075\tvalid_1's rmse: 5.99117\n",
      "[3550]\ttraining's rmse: 3.90966\tvalid_1's rmse: 5.98919\n",
      "[3600]\ttraining's rmse: 3.88877\tvalid_1's rmse: 5.98752\n",
      "[3650]\ttraining's rmse: 3.86843\tvalid_1's rmse: 5.98515\n",
      "[3700]\ttraining's rmse: 3.84826\tvalid_1's rmse: 5.98206\n",
      "[3750]\ttraining's rmse: 3.82906\tvalid_1's rmse: 5.98069\n",
      "[3800]\ttraining's rmse: 3.80836\tvalid_1's rmse: 5.98004\n",
      "[3850]\ttraining's rmse: 3.78883\tvalid_1's rmse: 5.97826\n",
      "[3900]\ttraining's rmse: 3.76972\tvalid_1's rmse: 5.97629\n",
      "[3950]\ttraining's rmse: 3.75079\tvalid_1's rmse: 5.97527\n",
      "[4000]\ttraining's rmse: 3.73152\tvalid_1's rmse: 5.97299\n",
      "[4050]\ttraining's rmse: 3.71291\tvalid_1's rmse: 5.97027\n",
      "[4100]\ttraining's rmse: 3.69359\tvalid_1's rmse: 5.96845\n",
      "[4150]\ttraining's rmse: 3.67566\tvalid_1's rmse: 5.967\n",
      "[4200]\ttraining's rmse: 3.65744\tvalid_1's rmse: 5.96511\n",
      "[4250]\ttraining's rmse: 3.63968\tvalid_1's rmse: 5.96328\n",
      "[4300]\ttraining's rmse: 3.62199\tvalid_1's rmse: 5.96198\n",
      "[4350]\ttraining's rmse: 3.60434\tvalid_1's rmse: 5.96095\n",
      "[4400]\ttraining's rmse: 3.58676\tvalid_1's rmse: 5.96042\n",
      "[4450]\ttraining's rmse: 3.56939\tvalid_1's rmse: 5.95814\n",
      "[4500]\ttraining's rmse: 3.55263\tvalid_1's rmse: 5.95742\n",
      "[4550]\ttraining's rmse: 3.53599\tvalid_1's rmse: 5.9565\n",
      "[4600]\ttraining's rmse: 3.51975\tvalid_1's rmse: 5.9551\n",
      "[4650]\ttraining's rmse: 3.50262\tvalid_1's rmse: 5.95252\n",
      "[4700]\ttraining's rmse: 3.48577\tvalid_1's rmse: 5.95098\n",
      "[4750]\ttraining's rmse: 3.46982\tvalid_1's rmse: 5.94952\n",
      "[4800]\ttraining's rmse: 3.45354\tvalid_1's rmse: 5.94803\n",
      "[4850]\ttraining's rmse: 3.43798\tvalid_1's rmse: 5.94701\n",
      "[4900]\ttraining's rmse: 3.42289\tvalid_1's rmse: 5.9461\n",
      "[4950]\ttraining's rmse: 3.40687\tvalid_1's rmse: 5.94495\n",
      "[5000]\ttraining's rmse: 3.39173\tvalid_1's rmse: 5.94367\n",
      "[5050]\ttraining's rmse: 3.37627\tvalid_1's rmse: 5.94211\n",
      "[5100]\ttraining's rmse: 3.36106\tvalid_1's rmse: 5.94103\n",
      "[5150]\ttraining's rmse: 3.3464\tvalid_1's rmse: 5.94086\n",
      "[5200]\ttraining's rmse: 3.33144\tvalid_1's rmse: 5.93912\n",
      "[5250]\ttraining's rmse: 3.31664\tvalid_1's rmse: 5.93864\n",
      "[5300]\ttraining's rmse: 3.30217\tvalid_1's rmse: 5.93724\n",
      "[5350]\ttraining's rmse: 3.28799\tvalid_1's rmse: 5.9361\n",
      "[5400]\ttraining's rmse: 3.27362\tvalid_1's rmse: 5.93467\n",
      "[5450]\ttraining's rmse: 3.25983\tvalid_1's rmse: 5.93506\n",
      "[5500]\ttraining's rmse: 3.24652\tvalid_1's rmse: 5.9344\n",
      "[5550]\ttraining's rmse: 3.23275\tvalid_1's rmse: 5.93508\n",
      "[5600]\ttraining's rmse: 3.21888\tvalid_1's rmse: 5.93662\n",
      "[5650]\ttraining's rmse: 3.20553\tvalid_1's rmse: 5.93591\n",
      "Early stopping, best iteration is:\n",
      "[5486]\ttraining's rmse: 3.25026\tvalid_1's rmse: 5.93414\n",
      "Train RMSE: 3.2502599032184727        Valida RMSE: 5.934140845642208\n",
      "Columns: ['emb_714', 'emb_432', 'emb_139', 'emb_587', 'emb_306', 'emb_321', 'emb_433', 'emb_45', 'emb_511', 'emb_168', 'emb_156', 'emb_177', 'emb_151', 'emb_600', 'emb_162', 'emb_295', 'emb_318', 'emb_326', 'emb_249', 'emb_583', 'emb_328', 'emb_29', 'emb_649', 'emb_665', 'emb_69', 'emb_580', 'emb_598', 'emb_495', 'emb_647', 'emb_554', 'emb_485', 'emb_541', 'emb_348', 'emb_675', 'emb_264', 'emb_193', 'emb_115', 'emb_64', 'diff_t', 'emb_288', 'emb_72', 'emb_155', 'emb_585', 'emb_59', 'emb_100', 'emb_97', 'emb_722', 'emb_88', 'emb_104', 'emb_559', 'emb_3', 'emb_429', 'emb_142', 'emb_407', 'emb_467', 'emb_451', 'emb_682', 'emb_522', 'emb_292', 'emb_458', 'emb_687', 'emb_444', 'emb_691', 'emb_514', 'emb_277', 'emb_323', 'emb_693', 'emb_241', 'emb_255', 'emb_91', 'emb_362', 'emb_82', 'emb_297', 'emb_259', 'emb_582', 'emb_99', 'emb_285', 'emb_570', 'emb_41', 'emb_105', 'emb_409', 'emb_445', 'emb_534', 'emb_110', 'emb_557', 'emb_388', 'emb_669', 'emb_590', 'emb_305', 'emb_86', 'emb_159', 'emb_525', 'emb_55', 'emb_50', 'emb_172', 'emb_279', 'emb_335', 'emb_133', 'emb_480', 'emb_537', 'emb_761', 'emb_767', 'emb_468', 'emb_494', 'emb_185', 'emb_401', 'emb_196', 'emb_353', 'emb_147', 'emb_561', 'emb_28', 'emb_596', 'emb_642', 'emb_599', 'emb_273', 'emb_271', 'emb_204', 'emb_607', 'emb_686', 'emb_616', 'emb_322', 'emb_230', 'emb_32', 'emb_556', 'emb_571', 'emb_361', 'emb_472', 'emb_276', 'emb_80', 'emb_446', 'emb_613', 'emb_762', 'emb_73', 'emb_562', 'emb_512', 'emb_548', 'emb_754', 'emb_194', 'emb_203', 'emb_332', 'emb_360', 'emb_415', 'emb_449', 'emb_560', 'emb_725', 'emb_157', 'emb_357', 'emb_400', 'emb_78', 'emb_572', 'emb_720', 'emb_688', 'emb_152', 'emb_439', 'emb_431', 'emb_57', 'emb_174', 'emb_158', 'emb_132', 'emb_66', 'emb_421', 'emb_763', 'emb_533', 'emb_459', 'emb_315', 'emb_12', 'emb_207', 'emb_317', 'emb_694', 'emb_56', 'emb_27', 'emb_68', 'emb_236', 'emb_130', 'emb_486', 'emb_527', 'emb_447', 'emb_251', 'emb_394', 'emb_452', 'emb_161', 'emb_503', 'emb_709', 'emb_416', 'emb_617', 'emb_681', 'emb_87', 'emb_742', 'emb_54', 'emb_414', 'emb_77', 'emb_146', 'emb_330', 'emb_635', 'emb_626', 'emb_84', 'emb_46', 'emb_354', 'emb_736', 'emb_118', 'emb_650', 'emb_532', 'emb_113', 'emb_475', 'emb_111', 'emb_364', 'emb_597', 'emb_622', 'emb_419', 'emb_717', 'emb_378', 'emb_192', 'emb_180', 'emb_555', 'emb_536', 'emb_623', 'emb_610', 'emb_413', 'emb_540', 'emb_674', 'emb_282', 'emb_643', 'emb_49', 'emb_748', 'emb_589', 'emb_187', 'emb_405', 'emb_499', 'emb_520', 'emb_44', 'emb_186', 'emb_546', 'emb_320', 'emb_746', 'emb_417', 'emb_201', 'emb_181', 'emb_516', 'emb_487', 'emb_558', 'emb_462', 'emb_191', 'emb_43', 'emb_202', 'emb_379', 'emb_76', 'emb_695', 'emb_275', 'emb_428', 'emb_165', 'emb_52', 'emb_23', 'emb_741', 'emb_237', 'emb_531', 'emb_175', 'emb_493', 'emb_471', 'emb_263', 'emb_550', 'emb_641', 'emb_340', 'emb_74', 'emb_344', 'emb_545', 'emb_2', 'emb_655', 'emb_257', 'emb_621', 'emb_327', 'emb_129', 'emb_718', 'emb_539', 'emb_666', 'emb_603', 'emb_112', 'emb_689', 'emb_606', 'emb_258', 'emb_301', 'emb_406', 'emb_604', 'emb_198', 'emb_591', 'emb_667', 'emb_355', 'emb_210', 'emb_140', 'emb_40', 'emb_373', 'emb_171', 'emb_309', 'emb_465', 'emb_543', 'emb_579', 'emb_584', 'emb_602', 'emb_544', 'emb_31', 'emb_569', 'emb_628', 'emb_424', 'emb_497', 'emb_437', 'emb_36', 'emb_254', 'emb_169', 'emb_154', 'emb_656', 'emb_338', 'emb_103', 'emb_398', 'emb_94', 'emb_566', 'emb_116', 'emb_238', 'emb_538', 'emb_753', 'emb_586', 'emb_34', 'emb_299', 'emb_9', 'emb_120', 'emb_712', 'emb_477', 'emb_303', 'emb_261', 'emb_455', 'emb_269', 'emb_163', 'emb_510', 'emb_418', 'emb_713', 'emb_500', 'emb_719', 'emb_744', 'ingredients_that_may_be_from_palm_oil_n', 'emb_611', 'emb_233', 'emb_408', 'emb_508', 'emb_731', 'emb_244', 'emb_221', 'emb_574', 'emb_102', 'emb_359', 'emb_95', 'emb_456', 'emb_425', 'emb_266', 'emb_294', 'emb_213', 'emb_399', 'emb_26', 'ingredients_from_palm_oil_n', 'emb_38', 'emb_716', 'emb_126', 'emb_206', 'emb_96', 'emb_135', 'emb_60', 'emb_235', 'emb_690', 'emb_33', 'emb_482', 'emb_392', 'emb_197', 'emb_345', 'emb_470', 'emb_247', 'emb_481', 'emb_4', 'emb_170', 'emb_15', 'emb_551', 'emb_123', 'emb_179', 'emb_624', 'emb_680', 'emb_128', 'emb_658', 'emb_250', 'emb_594', 'emb_521', 'emb_92', 'emb_483', 'emb_324', 'emb_149', 'emb_685', 'emb_200', 'emb_18', 'emb_389', 'emb_648', 'emb_612', 'emb_199', 'emb_374', 'emb_220', 'emb_625', 'emb_670', 'emb_751', 'emb_268', 'emb_308', 'emb_496', 'emb_387', 'emb_371', 'emb_339', 'emb_509', 'emb_438', 'emb_58', 'emb_61', 'emb_98', 'emb_565', 'emb_668', 'emb_404', 'emb_676', 'emb_307', 'emb_274', 'emb_764', 'emb_765', 'emb_37', 'emb_283', 'emb_83', 'emb_661', 'emb_747', 'emb_476', 'emb_316', 'emb_578', 'emb_11', 'emb_724', 'emb_402', 'emb_646', 'emb_260', 'emb_121', 'emb_298', 'emb_253', 'emb_410', 'emb_653', 'emb_239', 'emb_601', 'emb_662', 'emb_701', 'emb_153', 'emb_107', 'emb_85', 'emb_160', 'emb_517', 'emb_302', 'emb_632', 'emb_350', 'emb_188', 'emb_265', 'emb_311', 'emb_334', 'emb_51', 'emb_705', 'emb_683', 'emb_563', 'emb_535', 'emb_383', 'emb_217', 'emb_434', 'emb_526', 'emb_502', 'emb_501', 'emb_491', 'emb_138', 'emb_397', 'emb_310', 'emb_728', 'emb_234', 'emb_492', 'emb_20', 'emb_479', 'emb_367', 'emb_79', 'emb_524', 'emb_281', 'emb_341', 'emb_403', 'emb_6', 'emb_270', 'emb_141', 'emb_342', 'emb_506', 'emb_678', 'emb_654', 'emb_42', 'emb_343', 'emb_53', 'emb_750', 'emb_457', 'emb_638', 'emb_507', 'emb_150', 'emb_664', 'emb_660', 'emb_365', 'emb_393', 'emb_166', 'emb_289', 'emb_395', 'emb_730', 'emb_347', 'emb_464', 'emb_125', 'emb_707', 'emb_697', 'emb_376', 'emb_759', 'emb_290', 'emb_216', 'emb_671', 'emb_24', 'emb_618', 'emb_119', 'emb_35', 'emb_651', 'emb_14', 'emb_679', 'emb_659', 'emb_745', 'emb_48', 'emb_518', 'emb_450', 'emb_21', 'emb_93', 'emb_757', 'emb_463', 'emb_240', 'emb_164', 'emb_319', 'emb_325', 'emb_699', 'emb_605', 'emb_0', 'emb_22', 'emb_351', 'emb_183', 'emb_243', 'emb_256', 'emb_313', 'emb_189', 'emb_489', 'emb_564', 'emb_644', 'emb_528', 'emb_304', 'emb_692', 'emb_633', 'emb_443', 'emb_368', 'additives_n', 'emb_608', 'emb_504', 'emb_749', 'emb_229', 'emb_65', 'emb_331', 'emb_286', 'emb_702', 'emb_677', 'emb_453', 'emb_287', 'emb_71', 'emb_127', 'emb_90', 'emb_755', 'emb_176', 'emb_214', 'emb_639', 'emb_756', 'emb_484', 'emb_490', 'emb_114', 'emb_549', 'emb_454', 'emb_391', 'emb_637', 'emb_67', 'emb_291', 'emb_228', 'emb_478', 'emb_513', 'emb_629', 'emb_333', 'emb_346', 'emb_377', 'emb_440', 'emb_634', 'emb_684', 'emb_25', 'emb_735', 'emb_708', 'emb_696', 'emb_766', 'emb_101', 'emb_529', 'emb_16', 'emb_498', 'emb_734', 'emb_620', 'emb_448', 'emb_715', 'emb_381', 'emb_743', 'emb_252', 'emb_108', 'emb_293', 'emb_427', 'emb_136', 'emb_614', 'emb_473', 'emb_208', 'emb_469', 'emb_219', 'emb_117', 'emb_173', 'emb_519', 'emb_337', 'emb_356', 'emb_657', 'emb_627', 'emb_1', 'emb_222', 'emb_272', 'emb_706', 'emb_442', 'emb_144', 'emb_758', 'emb_225', 'emb_435', 'emb_384', 'emb_673', 'emb_411', 'emb_738', 'emb_593', 'emb_215', 'emb_218', 'emb_420', 'emb_430', 'emb_576', 'emb_205', 'emb_703', 'emb_62', 'emb_227', 'emb_167', 'emb_212', 'emb_134', 'emb_575', 'emb_145', 'emb_39', 'emb_231', 'emb_312', 'emb_567', 'emb_143', 'emb_314', 'emb_542', 'emb_573', 'emb_436', 'emb_547', 'emb_422', 'emb_733', 'emb_248', 'emb_737', 'emb_466', 'emb_278', 'emb_426', 'emb_137', 'emb_592', 'emb_386', 'emb_284', 'emb_246', 'emb_523', 'emb_8', 'emb_710', 'emb_122', 'emb_5', 'emb_296', 'emb_396', 'emb_17', 'emb_267', 'emb_505', 'emb_7', 'emb_698', 'emb_385', 'emb_19', 'emb_672', 'emb_636', 'emb_148', 'emb_577', 'emb_723', 'emb_652', 'emb_595', 'emb_369', 'emb_124', 'emb_640', 'emb_630', 'emb_47', 'emb_721', 'emb_375', 'emb_700', 'emb_224', 'emb_358', 'emb_349', 'emb_581', 'emb_530', 'emb_280', 'emb_631', 'emb_740', 'emb_10', 'emb_382', 'emb_232', 'emb_75', 'emb_195', 'emb_732', 'emb_619', 'emb_226', 'emb_615', 'emb_81', 'emb_423', 'emb_663', 'emb_131', 'emb_461', 'emb_729', 'emb_209', 'emb_352', 'emb_262', 'emb_366', 'emb_727', 'emb_300', 'emb_711', 'emb_370', 'emb_515', 'emb_30', 'emb_363', 'emb_553', 'emb_441', 'emb_223', 'emb_739', 'emb_609', 'emb_726', 'emb_372', 'emb_390', 'emb_412', 'emb_645', 'emb_190', 'emb_63', 'emb_752', 'emb_178', 'emb_380', 'emb_106', 'emb_336', 'emb_760', 'emb_460', 'emb_329', 'emb_70', 'emb_588', 'emb_474', 'emb_704', 'emb_211', 'emb_568', 'emb_89', 'emb_184', 'emb_182', 'emb_109', 'emb_245', 'emb_552', 'emb_242', 'emb_13', 'emb_488', 'label_states_en_brands', 'label_states_en_categories', 'label_states_en_characteristics', 'label_states_en_expiration date', 'label_states_en_general_complete', 'label_states_en_ingredients', 'label_pnns_groups_1', 'label_pnns_groups_2', 'label_states_en_packaging', 'label_states_en_packaging-code-', 'label_states_en_photo_upload', 'label_states_en_photo_validate', 'label_states_en_product name', 'label_states_en_quantity']\n",
      "Cat index: [772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785]\n",
      "---------- Training fold NÂº 2 ----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 196221\n",
      "[LightGBM] [Info] Number of data points in the train set: 81622, number of used features: 786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.169930\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's rmse: 7.14542\tvalid_1's rmse: 7.22901\n",
      "[100]\ttraining's rmse: 6.82198\tvalid_1's rmse: 6.96796\n",
      "[150]\ttraining's rmse: 6.63491\tvalid_1's rmse: 6.82724\n",
      "[200]\ttraining's rmse: 6.50186\tvalid_1's rmse: 6.74207\n",
      "[250]\ttraining's rmse: 6.39226\tvalid_1's rmse: 6.6741\n",
      "[300]\ttraining's rmse: 6.2954\tvalid_1's rmse: 6.6148\n",
      "[350]\ttraining's rmse: 6.20914\tvalid_1's rmse: 6.56807\n",
      "[400]\ttraining's rmse: 6.12831\tvalid_1's rmse: 6.52763\n",
      "[450]\ttraining's rmse: 6.05491\tvalid_1's rmse: 6.49649\n",
      "[500]\ttraining's rmse: 5.98832\tvalid_1's rmse: 6.46949\n",
      "[550]\ttraining's rmse: 5.92\tvalid_1's rmse: 6.43991\n",
      "[600]\ttraining's rmse: 5.8585\tvalid_1's rmse: 6.4174\n",
      "[650]\ttraining's rmse: 5.79987\tvalid_1's rmse: 6.3966\n",
      "[700]\ttraining's rmse: 5.74296\tvalid_1's rmse: 6.37641\n",
      "[750]\ttraining's rmse: 5.68963\tvalid_1's rmse: 6.35868\n",
      "[800]\ttraining's rmse: 5.6377\tvalid_1's rmse: 6.34144\n",
      "[850]\ttraining's rmse: 5.58486\tvalid_1's rmse: 6.32117\n",
      "[900]\ttraining's rmse: 5.53675\tvalid_1's rmse: 6.30704\n",
      "[950]\ttraining's rmse: 5.48806\tvalid_1's rmse: 6.29196\n",
      "[1000]\ttraining's rmse: 5.44122\tvalid_1's rmse: 6.27715\n",
      "[1050]\ttraining's rmse: 5.397\tvalid_1's rmse: 6.26743\n",
      "[1100]\ttraining's rmse: 5.35359\tvalid_1's rmse: 6.25516\n",
      "[1150]\ttraining's rmse: 5.31111\tvalid_1's rmse: 6.24451\n",
      "[1200]\ttraining's rmse: 5.26991\tvalid_1's rmse: 6.23263\n",
      "[1250]\ttraining's rmse: 5.22992\tvalid_1's rmse: 6.22372\n",
      "[1300]\ttraining's rmse: 5.19087\tvalid_1's rmse: 6.21425\n",
      "[1350]\ttraining's rmse: 5.15133\tvalid_1's rmse: 6.20323\n",
      "[1400]\ttraining's rmse: 5.11079\tvalid_1's rmse: 6.19188\n",
      "[1450]\ttraining's rmse: 5.0738\tvalid_1's rmse: 6.18441\n",
      "[1500]\ttraining's rmse: 5.03701\tvalid_1's rmse: 6.17826\n",
      "[1550]\ttraining's rmse: 5.0005\tvalid_1's rmse: 6.16905\n",
      "[1600]\ttraining's rmse: 4.96574\tvalid_1's rmse: 6.16181\n",
      "[1650]\ttraining's rmse: 4.9313\tvalid_1's rmse: 6.15681\n",
      "[1700]\ttraining's rmse: 4.89529\tvalid_1's rmse: 6.14945\n",
      "[1750]\ttraining's rmse: 4.86284\tvalid_1's rmse: 6.14345\n",
      "[1800]\ttraining's rmse: 4.82948\tvalid_1's rmse: 6.13365\n",
      "[1850]\ttraining's rmse: 4.79683\tvalid_1's rmse: 6.12683\n",
      "[1900]\ttraining's rmse: 4.76525\tvalid_1's rmse: 6.11927\n",
      "[1950]\ttraining's rmse: 4.73489\tvalid_1's rmse: 6.11569\n",
      "[2000]\ttraining's rmse: 4.70334\tvalid_1's rmse: 6.11047\n",
      "[2050]\ttraining's rmse: 4.67275\tvalid_1's rmse: 6.10288\n",
      "[2100]\ttraining's rmse: 4.64235\tvalid_1's rmse: 6.09939\n",
      "[2150]\ttraining's rmse: 4.61283\tvalid_1's rmse: 6.09425\n",
      "[2200]\ttraining's rmse: 4.58267\tvalid_1's rmse: 6.09002\n",
      "[2250]\ttraining's rmse: 4.55332\tvalid_1's rmse: 6.08581\n",
      "[2300]\ttraining's rmse: 4.52438\tvalid_1's rmse: 6.08334\n",
      "[2350]\ttraining's rmse: 4.49657\tvalid_1's rmse: 6.08097\n",
      "[2400]\ttraining's rmse: 4.46936\tvalid_1's rmse: 6.07778\n",
      "[2450]\ttraining's rmse: 4.44104\tvalid_1's rmse: 6.07383\n",
      "[2500]\ttraining's rmse: 4.414\tvalid_1's rmse: 6.06913\n",
      "[2550]\ttraining's rmse: 4.38669\tvalid_1's rmse: 6.06453\n",
      "[2600]\ttraining's rmse: 4.35994\tvalid_1's rmse: 6.05841\n",
      "[2650]\ttraining's rmse: 4.33483\tvalid_1's rmse: 6.05736\n",
      "[2700]\ttraining's rmse: 4.30876\tvalid_1's rmse: 6.05384\n",
      "[2750]\ttraining's rmse: 4.28405\tvalid_1's rmse: 6.05323\n",
      "[2800]\ttraining's rmse: 4.25892\tvalid_1's rmse: 6.05074\n",
      "[2850]\ttraining's rmse: 4.23493\tvalid_1's rmse: 6.04671\n",
      "[2900]\ttraining's rmse: 4.2094\tvalid_1's rmse: 6.04103\n",
      "[2950]\ttraining's rmse: 4.18605\tvalid_1's rmse: 6.03788\n",
      "[3000]\ttraining's rmse: 4.16201\tvalid_1's rmse: 6.03408\n",
      "[3050]\ttraining's rmse: 4.13913\tvalid_1's rmse: 6.03021\n",
      "[3100]\ttraining's rmse: 4.1157\tvalid_1's rmse: 6.02785\n",
      "[3150]\ttraining's rmse: 4.09268\tvalid_1's rmse: 6.02356\n",
      "[3200]\ttraining's rmse: 4.07005\tvalid_1's rmse: 6.0218\n",
      "[3250]\ttraining's rmse: 4.04698\tvalid_1's rmse: 6.01886\n",
      "[3300]\ttraining's rmse: 4.02448\tvalid_1's rmse: 6.0179\n",
      "[3350]\ttraining's rmse: 4.00302\tvalid_1's rmse: 6.01542\n",
      "[3400]\ttraining's rmse: 3.98105\tvalid_1's rmse: 6.01205\n",
      "[3450]\ttraining's rmse: 3.96003\tvalid_1's rmse: 6.00868\n",
      "[3500]\ttraining's rmse: 3.93961\tvalid_1's rmse: 6.00721\n",
      "[3550]\ttraining's rmse: 3.91817\tvalid_1's rmse: 6.00556\n",
      "[3600]\ttraining's rmse: 3.89747\tvalid_1's rmse: 6.00375\n",
      "[3650]\ttraining's rmse: 3.87825\tvalid_1's rmse: 6.00255\n",
      "[3700]\ttraining's rmse: 3.8578\tvalid_1's rmse: 6.00118\n",
      "[3750]\ttraining's rmse: 3.83796\tvalid_1's rmse: 5.99996\n",
      "[3800]\ttraining's rmse: 3.81816\tvalid_1's rmse: 5.99746\n",
      "[3850]\ttraining's rmse: 3.79812\tvalid_1's rmse: 5.99603\n",
      "[3900]\ttraining's rmse: 3.77918\tvalid_1's rmse: 5.99266\n",
      "[3950]\ttraining's rmse: 3.75966\tvalid_1's rmse: 5.99014\n",
      "[4000]\ttraining's rmse: 3.74184\tvalid_1's rmse: 5.98931\n",
      "[4050]\ttraining's rmse: 3.72267\tvalid_1's rmse: 5.9871\n",
      "[4100]\ttraining's rmse: 3.70325\tvalid_1's rmse: 5.98607\n",
      "[4150]\ttraining's rmse: 3.68477\tvalid_1's rmse: 5.98437\n",
      "[4200]\ttraining's rmse: 3.66628\tvalid_1's rmse: 5.98305\n",
      "[4250]\ttraining's rmse: 3.6479\tvalid_1's rmse: 5.98139\n",
      "[4300]\ttraining's rmse: 3.62977\tvalid_1's rmse: 5.9802\n",
      "[4350]\ttraining's rmse: 3.61246\tvalid_1's rmse: 5.97749\n",
      "[4400]\ttraining's rmse: 3.59454\tvalid_1's rmse: 5.97615\n",
      "[4450]\ttraining's rmse: 3.5767\tvalid_1's rmse: 5.97441\n",
      "[4500]\ttraining's rmse: 3.56013\tvalid_1's rmse: 5.97298\n",
      "[4550]\ttraining's rmse: 3.54293\tvalid_1's rmse: 5.97116\n",
      "[4600]\ttraining's rmse: 3.5261\tvalid_1's rmse: 5.97011\n",
      "[4650]\ttraining's rmse: 3.50978\tvalid_1's rmse: 5.96908\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4700]\ttraining's rmse: 3.49331\tvalid_1's rmse: 5.96672\n",
      "[4750]\ttraining's rmse: 3.47729\tvalid_1's rmse: 5.96456\n",
      "[4800]\ttraining's rmse: 3.46118\tvalid_1's rmse: 5.96394\n",
      "[4850]\ttraining's rmse: 3.44572\tvalid_1's rmse: 5.96307\n",
      "[4900]\ttraining's rmse: 3.43022\tvalid_1's rmse: 5.96208\n",
      "[4950]\ttraining's rmse: 3.41487\tvalid_1's rmse: 5.96171\n",
      "[5000]\ttraining's rmse: 3.39901\tvalid_1's rmse: 5.96044\n",
      "[5050]\ttraining's rmse: 3.38347\tvalid_1's rmse: 5.9605\n",
      "[5100]\ttraining's rmse: 3.36781\tvalid_1's rmse: 5.96011\n",
      "[5150]\ttraining's rmse: 3.35258\tvalid_1's rmse: 5.95867\n",
      "[5200]\ttraining's rmse: 3.33782\tvalid_1's rmse: 5.95699\n",
      "[5250]\ttraining's rmse: 3.32307\tvalid_1's rmse: 5.95718\n",
      "[5300]\ttraining's rmse: 3.30786\tvalid_1's rmse: 5.95459\n",
      "[5350]\ttraining's rmse: 3.29318\tvalid_1's rmse: 5.95342\n",
      "[5400]\ttraining's rmse: 3.27931\tvalid_1's rmse: 5.95212\n",
      "[5450]\ttraining's rmse: 3.26517\tvalid_1's rmse: 5.95134\n",
      "[5500]\ttraining's rmse: 3.2509\tvalid_1's rmse: 5.9501\n",
      "[5550]\ttraining's rmse: 3.23681\tvalid_1's rmse: 5.94884\n",
      "[5600]\ttraining's rmse: 3.22366\tvalid_1's rmse: 5.94755\n",
      "[5650]\ttraining's rmse: 3.21051\tvalid_1's rmse: 5.94749\n",
      "[5700]\ttraining's rmse: 3.19667\tvalid_1's rmse: 5.94633\n",
      "[5750]\ttraining's rmse: 3.18312\tvalid_1's rmse: 5.94605\n",
      "[5800]\ttraining's rmse: 3.16996\tvalid_1's rmse: 5.94438\n",
      "[5850]\ttraining's rmse: 3.15706\tvalid_1's rmse: 5.94421\n",
      "[5900]\ttraining's rmse: 3.14441\tvalid_1's rmse: 5.94416\n",
      "[5950]\ttraining's rmse: 3.13178\tvalid_1's rmse: 5.94377\n",
      "[6000]\ttraining's rmse: 3.11911\tvalid_1's rmse: 5.94187\n",
      "[6050]\ttraining's rmse: 3.1061\tvalid_1's rmse: 5.94083\n",
      "[6100]\ttraining's rmse: 3.09368\tvalid_1's rmse: 5.93949\n",
      "[6150]\ttraining's rmse: 3.08135\tvalid_1's rmse: 5.93773\n",
      "[6200]\ttraining's rmse: 3.06883\tvalid_1's rmse: 5.93719\n",
      "[6250]\ttraining's rmse: 3.05729\tvalid_1's rmse: 5.93664\n",
      "[6300]\ttraining's rmse: 3.04541\tvalid_1's rmse: 5.93519\n",
      "[6350]\ttraining's rmse: 3.03352\tvalid_1's rmse: 5.93472\n",
      "[6400]\ttraining's rmse: 3.02183\tvalid_1's rmse: 5.93401\n",
      "[6450]\ttraining's rmse: 3.00995\tvalid_1's rmse: 5.93225\n",
      "[6500]\ttraining's rmse: 2.99785\tvalid_1's rmse: 5.93079\n",
      "[6550]\ttraining's rmse: 2.98654\tvalid_1's rmse: 5.93025\n",
      "[6600]\ttraining's rmse: 2.97429\tvalid_1's rmse: 5.9298\n",
      "[6650]\ttraining's rmse: 2.96321\tvalid_1's rmse: 5.92953\n",
      "[6700]\ttraining's rmse: 2.95224\tvalid_1's rmse: 5.92878\n",
      "[6750]\ttraining's rmse: 2.94106\tvalid_1's rmse: 5.92917\n",
      "[6800]\ttraining's rmse: 2.93012\tvalid_1's rmse: 5.92798\n",
      "[6850]\ttraining's rmse: 2.91906\tvalid_1's rmse: 5.92724\n",
      "[6900]\ttraining's rmse: 2.90852\tvalid_1's rmse: 5.92778\n",
      "[6950]\ttraining's rmse: 2.89779\tvalid_1's rmse: 5.92765\n",
      "[7000]\ttraining's rmse: 2.88758\tvalid_1's rmse: 5.92682\n",
      "[7050]\ttraining's rmse: 2.8778\tvalid_1's rmse: 5.92599\n",
      "[7100]\ttraining's rmse: 2.86717\tvalid_1's rmse: 5.92503\n",
      "[7150]\ttraining's rmse: 2.85659\tvalid_1's rmse: 5.92445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7200]\ttraining's rmse: 2.84674\tvalid_1's rmse: 5.92315\n",
      "[7250]\ttraining's rmse: 2.83721\tvalid_1's rmse: 5.92298\n",
      "[7300]\ttraining's rmse: 2.82681\tvalid_1's rmse: 5.92213\n",
      "[7350]\ttraining's rmse: 2.81743\tvalid_1's rmse: 5.92207\n",
      "[7400]\ttraining's rmse: 2.80714\tvalid_1's rmse: 5.92162\n",
      "[7450]\ttraining's rmse: 2.79732\tvalid_1's rmse: 5.9218\n",
      "[7500]\ttraining's rmse: 2.78777\tvalid_1's rmse: 5.92111\n",
      "[7550]\ttraining's rmse: 2.7785\tvalid_1's rmse: 5.92095\n",
      "[7600]\ttraining's rmse: 2.76921\tvalid_1's rmse: 5.92102\n",
      "[7650]\ttraining's rmse: 2.76002\tvalid_1's rmse: 5.9196\n",
      "[7700]\ttraining's rmse: 2.75058\tvalid_1's rmse: 5.91847\n",
      "[7750]\ttraining's rmse: 2.74152\tvalid_1's rmse: 5.91763\n",
      "[7800]\ttraining's rmse: 2.73277\tvalid_1's rmse: 5.91784\n",
      "[7850]\ttraining's rmse: 2.72378\tvalid_1's rmse: 5.91681\n",
      "[7900]\ttraining's rmse: 2.71482\tvalid_1's rmse: 5.91623\n",
      "[7950]\ttraining's rmse: 2.70595\tvalid_1's rmse: 5.91559\n",
      "[8000]\ttraining's rmse: 2.69722\tvalid_1's rmse: 5.91486\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[8000]\ttraining's rmse: 2.69722\tvalid_1's rmse: 5.91486\n",
      "Train RMSE: 2.697216781277343        Valida RMSE: 5.914860067942863\n",
      "Columns: ['emb_714', 'emb_432', 'emb_139', 'emb_587', 'emb_306', 'emb_321', 'emb_433', 'emb_45', 'emb_511', 'emb_168', 'emb_156', 'emb_177', 'emb_151', 'emb_600', 'emb_162', 'emb_295', 'emb_318', 'emb_326', 'emb_249', 'emb_583', 'emb_328', 'emb_29', 'emb_649', 'emb_665', 'emb_69', 'emb_580', 'emb_598', 'emb_495', 'emb_647', 'emb_554', 'emb_485', 'emb_541', 'emb_348', 'emb_675', 'emb_264', 'emb_193', 'emb_115', 'emb_64', 'diff_t', 'emb_288', 'emb_72', 'emb_155', 'emb_585', 'emb_59', 'emb_100', 'emb_97', 'emb_722', 'emb_88', 'emb_104', 'emb_559', 'emb_3', 'emb_429', 'emb_142', 'emb_407', 'emb_467', 'emb_451', 'emb_682', 'emb_522', 'emb_292', 'emb_458', 'emb_687', 'emb_444', 'emb_691', 'emb_514', 'emb_277', 'emb_323', 'emb_693', 'emb_241', 'emb_255', 'emb_91', 'emb_362', 'emb_82', 'emb_297', 'emb_259', 'emb_582', 'emb_99', 'emb_285', 'emb_570', 'emb_41', 'emb_105', 'emb_409', 'emb_445', 'emb_534', 'emb_110', 'emb_557', 'emb_388', 'emb_669', 'emb_590', 'emb_305', 'emb_86', 'emb_159', 'emb_525', 'emb_55', 'emb_50', 'emb_172', 'emb_279', 'emb_335', 'emb_133', 'emb_480', 'emb_537', 'emb_761', 'emb_767', 'emb_468', 'emb_494', 'emb_185', 'emb_401', 'emb_196', 'emb_353', 'emb_147', 'emb_561', 'emb_28', 'emb_596', 'emb_642', 'emb_599', 'emb_273', 'emb_271', 'emb_204', 'emb_607', 'emb_686', 'emb_616', 'emb_322', 'emb_230', 'emb_32', 'emb_556', 'emb_571', 'emb_361', 'emb_472', 'emb_276', 'emb_80', 'emb_446', 'emb_613', 'emb_762', 'emb_73', 'emb_562', 'emb_512', 'emb_548', 'emb_754', 'emb_194', 'emb_203', 'emb_332', 'emb_360', 'emb_415', 'emb_449', 'emb_560', 'emb_725', 'emb_157', 'emb_357', 'emb_400', 'emb_78', 'emb_572', 'emb_720', 'emb_688', 'emb_152', 'emb_439', 'emb_431', 'emb_57', 'emb_174', 'emb_158', 'emb_132', 'emb_66', 'emb_421', 'emb_763', 'emb_533', 'emb_459', 'emb_315', 'emb_12', 'emb_207', 'emb_317', 'emb_694', 'emb_56', 'emb_27', 'emb_68', 'emb_236', 'emb_130', 'emb_486', 'emb_527', 'emb_447', 'emb_251', 'emb_394', 'emb_452', 'emb_161', 'emb_503', 'emb_709', 'emb_416', 'emb_617', 'emb_681', 'emb_87', 'emb_742', 'emb_54', 'emb_414', 'emb_77', 'emb_146', 'emb_330', 'emb_635', 'emb_626', 'emb_84', 'emb_46', 'emb_354', 'emb_736', 'emb_118', 'emb_650', 'emb_532', 'emb_113', 'emb_475', 'emb_111', 'emb_364', 'emb_597', 'emb_622', 'emb_419', 'emb_717', 'emb_378', 'emb_192', 'emb_180', 'emb_555', 'emb_536', 'emb_623', 'emb_610', 'emb_413', 'emb_540', 'emb_674', 'emb_282', 'emb_643', 'emb_49', 'emb_748', 'emb_589', 'emb_187', 'emb_405', 'emb_499', 'emb_520', 'emb_44', 'emb_186', 'emb_546', 'emb_320', 'emb_746', 'emb_417', 'emb_201', 'emb_181', 'emb_516', 'emb_487', 'emb_558', 'emb_462', 'emb_191', 'emb_43', 'emb_202', 'emb_379', 'emb_76', 'emb_695', 'emb_275', 'emb_428', 'emb_165', 'emb_52', 'emb_23', 'emb_741', 'emb_237', 'emb_531', 'emb_175', 'emb_493', 'emb_471', 'emb_263', 'emb_550', 'emb_641', 'emb_340', 'emb_74', 'emb_344', 'emb_545', 'emb_2', 'emb_655', 'emb_257', 'emb_621', 'emb_327', 'emb_129', 'emb_718', 'emb_539', 'emb_666', 'emb_603', 'emb_112', 'emb_689', 'emb_606', 'emb_258', 'emb_301', 'emb_406', 'emb_604', 'emb_198', 'emb_591', 'emb_667', 'emb_355', 'emb_210', 'emb_140', 'emb_40', 'emb_373', 'emb_171', 'emb_309', 'emb_465', 'emb_543', 'emb_579', 'emb_584', 'emb_602', 'emb_544', 'emb_31', 'emb_569', 'emb_628', 'emb_424', 'emb_497', 'emb_437', 'emb_36', 'emb_254', 'emb_169', 'emb_154', 'emb_656', 'emb_338', 'emb_103', 'emb_398', 'emb_94', 'emb_566', 'emb_116', 'emb_238', 'emb_538', 'emb_753', 'emb_586', 'emb_34', 'emb_299', 'emb_9', 'emb_120', 'emb_712', 'emb_477', 'emb_303', 'emb_261', 'emb_455', 'emb_269', 'emb_163', 'emb_510', 'emb_418', 'emb_713', 'emb_500', 'emb_719', 'emb_744', 'ingredients_that_may_be_from_palm_oil_n', 'emb_611', 'emb_233', 'emb_408', 'emb_508', 'emb_731', 'emb_244', 'emb_221', 'emb_574', 'emb_102', 'emb_359', 'emb_95', 'emb_456', 'emb_425', 'emb_266', 'emb_294', 'emb_213', 'emb_399', 'emb_26', 'ingredients_from_palm_oil_n', 'emb_38', 'emb_716', 'emb_126', 'emb_206', 'emb_96', 'emb_135', 'emb_60', 'emb_235', 'emb_690', 'emb_33', 'emb_482', 'emb_392', 'emb_197', 'emb_345', 'emb_470', 'emb_247', 'emb_481', 'emb_4', 'emb_170', 'emb_15', 'emb_551', 'emb_123', 'emb_179', 'emb_624', 'emb_680', 'emb_128', 'emb_658', 'emb_250', 'emb_594', 'emb_521', 'emb_92', 'emb_483', 'emb_324', 'emb_149', 'emb_685', 'emb_200', 'emb_18', 'emb_389', 'emb_648', 'emb_612', 'emb_199', 'emb_374', 'emb_220', 'emb_625', 'emb_670', 'emb_751', 'emb_268', 'emb_308', 'emb_496', 'emb_387', 'emb_371', 'emb_339', 'emb_509', 'emb_438', 'emb_58', 'emb_61', 'emb_98', 'emb_565', 'emb_668', 'emb_404', 'emb_676', 'emb_307', 'emb_274', 'emb_764', 'emb_765', 'emb_37', 'emb_283', 'emb_83', 'emb_661', 'emb_747', 'emb_476', 'emb_316', 'emb_578', 'emb_11', 'emb_724', 'emb_402', 'emb_646', 'emb_260', 'emb_121', 'emb_298', 'emb_253', 'emb_410', 'emb_653', 'emb_239', 'emb_601', 'emb_662', 'emb_701', 'emb_153', 'emb_107', 'emb_85', 'emb_160', 'emb_517', 'emb_302', 'emb_632', 'emb_350', 'emb_188', 'emb_265', 'emb_311', 'emb_334', 'emb_51', 'emb_705', 'emb_683', 'emb_563', 'emb_535', 'emb_383', 'emb_217', 'emb_434', 'emb_526', 'emb_502', 'emb_501', 'emb_491', 'emb_138', 'emb_397', 'emb_310', 'emb_728', 'emb_234', 'emb_492', 'emb_20', 'emb_479', 'emb_367', 'emb_79', 'emb_524', 'emb_281', 'emb_341', 'emb_403', 'emb_6', 'emb_270', 'emb_141', 'emb_342', 'emb_506', 'emb_678', 'emb_654', 'emb_42', 'emb_343', 'emb_53', 'emb_750', 'emb_457', 'emb_638', 'emb_507', 'emb_150', 'emb_664', 'emb_660', 'emb_365', 'emb_393', 'emb_166', 'emb_289', 'emb_395', 'emb_730', 'emb_347', 'emb_464', 'emb_125', 'emb_707', 'emb_697', 'emb_376', 'emb_759', 'emb_290', 'emb_216', 'emb_671', 'emb_24', 'emb_618', 'emb_119', 'emb_35', 'emb_651', 'emb_14', 'emb_679', 'emb_659', 'emb_745', 'emb_48', 'emb_518', 'emb_450', 'emb_21', 'emb_93', 'emb_757', 'emb_463', 'emb_240', 'emb_164', 'emb_319', 'emb_325', 'emb_699', 'emb_605', 'emb_0', 'emb_22', 'emb_351', 'emb_183', 'emb_243', 'emb_256', 'emb_313', 'emb_189', 'emb_489', 'emb_564', 'emb_644', 'emb_528', 'emb_304', 'emb_692', 'emb_633', 'emb_443', 'emb_368', 'additives_n', 'emb_608', 'emb_504', 'emb_749', 'emb_229', 'emb_65', 'emb_331', 'emb_286', 'emb_702', 'emb_677', 'emb_453', 'emb_287', 'emb_71', 'emb_127', 'emb_90', 'emb_755', 'emb_176', 'emb_214', 'emb_639', 'emb_756', 'emb_484', 'emb_490', 'emb_114', 'emb_549', 'emb_454', 'emb_391', 'emb_637', 'emb_67', 'emb_291', 'emb_228', 'emb_478', 'emb_513', 'emb_629', 'emb_333', 'emb_346', 'emb_377', 'emb_440', 'emb_634', 'emb_684', 'emb_25', 'emb_735', 'emb_708', 'emb_696', 'emb_766', 'emb_101', 'emb_529', 'emb_16', 'emb_498', 'emb_734', 'emb_620', 'emb_448', 'emb_715', 'emb_381', 'emb_743', 'emb_252', 'emb_108', 'emb_293', 'emb_427', 'emb_136', 'emb_614', 'emb_473', 'emb_208', 'emb_469', 'emb_219', 'emb_117', 'emb_173', 'emb_519', 'emb_337', 'emb_356', 'emb_657', 'emb_627', 'emb_1', 'emb_222', 'emb_272', 'emb_706', 'emb_442', 'emb_144', 'emb_758', 'emb_225', 'emb_435', 'emb_384', 'emb_673', 'emb_411', 'emb_738', 'emb_593', 'emb_215', 'emb_218', 'emb_420', 'emb_430', 'emb_576', 'emb_205', 'emb_703', 'emb_62', 'emb_227', 'emb_167', 'emb_212', 'emb_134', 'emb_575', 'emb_145', 'emb_39', 'emb_231', 'emb_312', 'emb_567', 'emb_143', 'emb_314', 'emb_542', 'emb_573', 'emb_436', 'emb_547', 'emb_422', 'emb_733', 'emb_248', 'emb_737', 'emb_466', 'emb_278', 'emb_426', 'emb_137', 'emb_592', 'emb_386', 'emb_284', 'emb_246', 'emb_523', 'emb_8', 'emb_710', 'emb_122', 'emb_5', 'emb_296', 'emb_396', 'emb_17', 'emb_267', 'emb_505', 'emb_7', 'emb_698', 'emb_385', 'emb_19', 'emb_672', 'emb_636', 'emb_148', 'emb_577', 'emb_723', 'emb_652', 'emb_595', 'emb_369', 'emb_124', 'emb_640', 'emb_630', 'emb_47', 'emb_721', 'emb_375', 'emb_700', 'emb_224', 'emb_358', 'emb_349', 'emb_581', 'emb_530', 'emb_280', 'emb_631', 'emb_740', 'emb_10', 'emb_382', 'emb_232', 'emb_75', 'emb_195', 'emb_732', 'emb_619', 'emb_226', 'emb_615', 'emb_81', 'emb_423', 'emb_663', 'emb_131', 'emb_461', 'emb_729', 'emb_209', 'emb_352', 'emb_262', 'emb_366', 'emb_727', 'emb_300', 'emb_711', 'emb_370', 'emb_515', 'emb_30', 'emb_363', 'emb_553', 'emb_441', 'emb_223', 'emb_739', 'emb_609', 'emb_726', 'emb_372', 'emb_390', 'emb_412', 'emb_645', 'emb_190', 'emb_63', 'emb_752', 'emb_178', 'emb_380', 'emb_106', 'emb_336', 'emb_760', 'emb_460', 'emb_329', 'emb_70', 'emb_588', 'emb_474', 'emb_704', 'emb_211', 'emb_568', 'emb_89', 'emb_184', 'emb_182', 'emb_109', 'emb_245', 'emb_552', 'emb_242', 'emb_13', 'emb_488', 'label_states_en_brands', 'label_states_en_categories', 'label_states_en_characteristics', 'label_states_en_expiration date', 'label_states_en_general_complete', 'label_states_en_ingredients', 'label_pnns_groups_1', 'label_pnns_groups_2', 'label_states_en_packaging', 'label_states_en_packaging-code-', 'label_states_en_photo_upload', 'label_states_en_photo_validate', 'label_states_en_product name', 'label_states_en_quantity']\n",
      "Cat index: [772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785]\n",
      "---------- Training fold NÂº 3 ----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 196221\n",
      "[LightGBM] [Info] Number of data points in the train set: 81622, number of used features: 786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.171253\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's rmse: 7.15605\tvalid_1's rmse: 7.20285\n",
      "[100]\ttraining's rmse: 6.83253\tvalid_1's rmse: 6.92401\n",
      "[150]\ttraining's rmse: 6.65122\tvalid_1's rmse: 6.78626\n",
      "[200]\ttraining's rmse: 6.51673\tvalid_1's rmse: 6.69902\n",
      "[250]\ttraining's rmse: 6.40788\tvalid_1's rmse: 6.63087\n",
      "[300]\ttraining's rmse: 6.30966\tvalid_1's rmse: 6.57792\n",
      "[350]\ttraining's rmse: 6.22475\tvalid_1's rmse: 6.53299\n",
      "[400]\ttraining's rmse: 6.14233\tvalid_1's rmse: 6.49271\n",
      "[450]\ttraining's rmse: 6.06788\tvalid_1's rmse: 6.4577\n",
      "[500]\ttraining's rmse: 5.99605\tvalid_1's rmse: 6.4287\n",
      "[550]\ttraining's rmse: 5.93071\tvalid_1's rmse: 6.40362\n",
      "[600]\ttraining's rmse: 5.86737\tvalid_1's rmse: 6.37744\n",
      "[650]\ttraining's rmse: 5.80526\tvalid_1's rmse: 6.35132\n",
      "[700]\ttraining's rmse: 5.74824\tvalid_1's rmse: 6.33386\n",
      "[750]\ttraining's rmse: 5.69346\tvalid_1's rmse: 6.31412\n",
      "[800]\ttraining's rmse: 5.63625\tvalid_1's rmse: 6.29351\n",
      "[850]\ttraining's rmse: 5.58538\tvalid_1's rmse: 6.27964\n",
      "[900]\ttraining's rmse: 5.53766\tvalid_1's rmse: 6.2677\n",
      "[950]\ttraining's rmse: 5.49092\tvalid_1's rmse: 6.2539\n",
      "[1000]\ttraining's rmse: 5.44254\tvalid_1's rmse: 6.23892\n",
      "[1050]\ttraining's rmse: 5.39783\tvalid_1's rmse: 6.2238\n",
      "[1100]\ttraining's rmse: 5.35153\tvalid_1's rmse: 6.21131\n",
      "[1150]\ttraining's rmse: 5.30761\tvalid_1's rmse: 6.2017\n",
      "[1200]\ttraining's rmse: 5.26589\tvalid_1's rmse: 6.19028\n",
      "[1250]\ttraining's rmse: 5.22548\tvalid_1's rmse: 6.1819\n",
      "[1300]\ttraining's rmse: 5.18643\tvalid_1's rmse: 6.17248\n",
      "[1350]\ttraining's rmse: 5.14537\tvalid_1's rmse: 6.16198\n",
      "[1400]\ttraining's rmse: 5.10615\tvalid_1's rmse: 6.15241\n",
      "[1450]\ttraining's rmse: 5.06936\tvalid_1's rmse: 6.14442\n",
      "[1500]\ttraining's rmse: 5.03325\tvalid_1's rmse: 6.13698\n",
      "[1550]\ttraining's rmse: 4.99684\tvalid_1's rmse: 6.12935\n",
      "[1600]\ttraining's rmse: 4.96006\tvalid_1's rmse: 6.12214\n",
      "[1650]\ttraining's rmse: 4.92552\tvalid_1's rmse: 6.11496\n",
      "[1700]\ttraining's rmse: 4.89061\tvalid_1's rmse: 6.10897\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1750]\ttraining's rmse: 4.85455\tvalid_1's rmse: 6.10094\n",
      "[1800]\ttraining's rmse: 4.82062\tvalid_1's rmse: 6.09509\n",
      "[1850]\ttraining's rmse: 4.78698\tvalid_1's rmse: 6.08686\n",
      "[1900]\ttraining's rmse: 4.75497\tvalid_1's rmse: 6.08241\n",
      "[1950]\ttraining's rmse: 4.72423\tvalid_1's rmse: 6.07706\n",
      "[2000]\ttraining's rmse: 4.69375\tvalid_1's rmse: 6.07254\n",
      "[2050]\ttraining's rmse: 4.66381\tvalid_1's rmse: 6.06714\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2100]\ttraining's rmse: 4.63509\tvalid_1's rmse: 6.06254\n",
      "[2150]\ttraining's rmse: 4.60466\tvalid_1's rmse: 6.0565\n",
      "[2200]\ttraining's rmse: 4.57527\tvalid_1's rmse: 6.05414\n",
      "[2250]\ttraining's rmse: 4.54587\tvalid_1's rmse: 6.04748\n",
      "[2300]\ttraining's rmse: 4.51695\tvalid_1's rmse: 6.04176\n",
      "[2350]\ttraining's rmse: 4.48953\tvalid_1's rmse: 6.03767\n",
      "[2400]\ttraining's rmse: 4.46196\tvalid_1's rmse: 6.03351\n",
      "[2450]\ttraining's rmse: 4.43491\tvalid_1's rmse: 6.02989\n",
      "[2500]\ttraining's rmse: 4.40735\tvalid_1's rmse: 6.02623\n",
      "[2550]\ttraining's rmse: 4.38068\tvalid_1's rmse: 6.02201\n",
      "[2600]\ttraining's rmse: 4.35468\tvalid_1's rmse: 6.01994\n",
      "[2650]\ttraining's rmse: 4.32877\tvalid_1's rmse: 6.01606\n",
      "[2700]\ttraining's rmse: 4.30309\tvalid_1's rmse: 6.01254\n",
      "[2750]\ttraining's rmse: 4.27825\tvalid_1's rmse: 6.01052\n",
      "[2800]\ttraining's rmse: 4.25297\tvalid_1's rmse: 6.00731\n",
      "[2850]\ttraining's rmse: 4.22884\tvalid_1's rmse: 6.00404\n",
      "[2900]\ttraining's rmse: 4.20542\tvalid_1's rmse: 6.00003\n",
      "[2950]\ttraining's rmse: 4.17991\tvalid_1's rmse: 5.99665\n",
      "[3000]\ttraining's rmse: 4.15639\tvalid_1's rmse: 5.99362\n",
      "[3050]\ttraining's rmse: 4.13304\tvalid_1's rmse: 5.99137\n",
      "[3100]\ttraining's rmse: 4.10857\tvalid_1's rmse: 5.9885\n",
      "[3150]\ttraining's rmse: 4.08598\tvalid_1's rmse: 5.98566\n",
      "[3200]\ttraining's rmse: 4.06304\tvalid_1's rmse: 5.98208\n",
      "[3250]\ttraining's rmse: 4.04124\tvalid_1's rmse: 5.97944\n",
      "[3300]\ttraining's rmse: 4.0195\tvalid_1's rmse: 5.97796\n",
      "[3350]\ttraining's rmse: 3.99712\tvalid_1's rmse: 5.97525\n",
      "[3400]\ttraining's rmse: 3.97621\tvalid_1's rmse: 5.97327\n",
      "[3450]\ttraining's rmse: 3.95493\tvalid_1's rmse: 5.97175\n",
      "[3500]\ttraining's rmse: 3.93292\tvalid_1's rmse: 5.96871\n",
      "[3550]\ttraining's rmse: 3.91187\tvalid_1's rmse: 5.96758\n",
      "[3600]\ttraining's rmse: 3.89147\tvalid_1's rmse: 5.96551\n",
      "[3650]\ttraining's rmse: 3.87084\tvalid_1's rmse: 5.96367\n",
      "[3700]\ttraining's rmse: 3.85001\tvalid_1's rmse: 5.96016\n",
      "[3750]\ttraining's rmse: 3.82959\tvalid_1's rmse: 5.95825\n",
      "[3800]\ttraining's rmse: 3.80961\tvalid_1's rmse: 5.95582\n",
      "[3850]\ttraining's rmse: 3.79106\tvalid_1's rmse: 5.95543\n",
      "[3900]\ttraining's rmse: 3.77217\tvalid_1's rmse: 5.95405\n",
      "[3950]\ttraining's rmse: 3.75205\tvalid_1's rmse: 5.9531\n",
      "[4000]\ttraining's rmse: 3.73241\tvalid_1's rmse: 5.95022\n",
      "[4050]\ttraining's rmse: 3.71404\tvalid_1's rmse: 5.94788\n",
      "[4100]\ttraining's rmse: 3.69436\tvalid_1's rmse: 5.94578\n",
      "[4150]\ttraining's rmse: 3.67584\tvalid_1's rmse: 5.94437\n",
      "[4200]\ttraining's rmse: 3.65807\tvalid_1's rmse: 5.9413\n",
      "[4250]\ttraining's rmse: 3.63989\tvalid_1's rmse: 5.93983\n",
      "[4300]\ttraining's rmse: 3.62172\tvalid_1's rmse: 5.93804\n",
      "[4350]\ttraining's rmse: 3.60373\tvalid_1's rmse: 5.93603\n",
      "[4400]\ttraining's rmse: 3.58526\tvalid_1's rmse: 5.93553\n",
      "[4450]\ttraining's rmse: 3.56739\tvalid_1's rmse: 5.935\n",
      "[4500]\ttraining's rmse: 3.55045\tvalid_1's rmse: 5.93339\n",
      "[4550]\ttraining's rmse: 3.53384\tvalid_1's rmse: 5.93266\n",
      "[4600]\ttraining's rmse: 3.51696\tvalid_1's rmse: 5.93022\n",
      "[4650]\ttraining's rmse: 3.50018\tvalid_1's rmse: 5.9279\n",
      "[4700]\ttraining's rmse: 3.48429\tvalid_1's rmse: 5.92665\n",
      "[4750]\ttraining's rmse: 3.46854\tvalid_1's rmse: 5.92532\n",
      "[4800]\ttraining's rmse: 3.45239\tvalid_1's rmse: 5.92468\n",
      "[4850]\ttraining's rmse: 3.4366\tvalid_1's rmse: 5.92359\n",
      "[4900]\ttraining's rmse: 3.42045\tvalid_1's rmse: 5.92115\n",
      "[4950]\ttraining's rmse: 3.40456\tvalid_1's rmse: 5.92001\n",
      "[5000]\ttraining's rmse: 3.38958\tvalid_1's rmse: 5.91831\n",
      "[5050]\ttraining's rmse: 3.3744\tvalid_1's rmse: 5.91628\n",
      "[5100]\ttraining's rmse: 3.35903\tvalid_1's rmse: 5.91585\n",
      "[5150]\ttraining's rmse: 3.34382\tvalid_1's rmse: 5.9155\n",
      "[5200]\ttraining's rmse: 3.32883\tvalid_1's rmse: 5.91532\n",
      "[5250]\ttraining's rmse: 3.31438\tvalid_1's rmse: 5.91322\n",
      "[5300]\ttraining's rmse: 3.29931\tvalid_1's rmse: 5.91132\n",
      "[5350]\ttraining's rmse: 3.2842\tvalid_1's rmse: 5.91042\n",
      "[5400]\ttraining's rmse: 3.26973\tvalid_1's rmse: 5.90957\n",
      "[5450]\ttraining's rmse: 3.25556\tvalid_1's rmse: 5.9084\n",
      "[5500]\ttraining's rmse: 3.24207\tvalid_1's rmse: 5.90813\n",
      "[5550]\ttraining's rmse: 3.22833\tvalid_1's rmse: 5.90719\n",
      "[5600]\ttraining's rmse: 3.21455\tvalid_1's rmse: 5.90636\n",
      "[5650]\ttraining's rmse: 3.20123\tvalid_1's rmse: 5.90465\n",
      "[5700]\ttraining's rmse: 3.18836\tvalid_1's rmse: 5.90372\n",
      "[5750]\ttraining's rmse: 3.17499\tvalid_1's rmse: 5.90244\n",
      "[5800]\ttraining's rmse: 3.16173\tvalid_1's rmse: 5.90139\n",
      "[5850]\ttraining's rmse: 3.14868\tvalid_1's rmse: 5.9001\n",
      "[5900]\ttraining's rmse: 3.13551\tvalid_1's rmse: 5.89898\n",
      "[5950]\ttraining's rmse: 3.12203\tvalid_1's rmse: 5.89891\n",
      "[6000]\ttraining's rmse: 3.10952\tvalid_1's rmse: 5.89836\n",
      "[6050]\ttraining's rmse: 3.09695\tvalid_1's rmse: 5.89664\n",
      "[6100]\ttraining's rmse: 3.08359\tvalid_1's rmse: 5.8964\n",
      "[6150]\ttraining's rmse: 3.07127\tvalid_1's rmse: 5.89559\n",
      "[6200]\ttraining's rmse: 3.05934\tvalid_1's rmse: 5.89388\n",
      "[6250]\ttraining's rmse: 3.04722\tvalid_1's rmse: 5.89349\n",
      "[6300]\ttraining's rmse: 3.03502\tvalid_1's rmse: 5.89346\n",
      "[6350]\ttraining's rmse: 3.02311\tvalid_1's rmse: 5.89355\n",
      "[6400]\ttraining's rmse: 3.01082\tvalid_1's rmse: 5.89259\n",
      "[6450]\ttraining's rmse: 2.9989\tvalid_1's rmse: 5.89168\n",
      "[6500]\ttraining's rmse: 2.98752\tvalid_1's rmse: 5.8901\n",
      "[6550]\ttraining's rmse: 2.97559\tvalid_1's rmse: 5.88928\n",
      "[6600]\ttraining's rmse: 2.96337\tvalid_1's rmse: 5.88852\n",
      "[6650]\ttraining's rmse: 2.95199\tvalid_1's rmse: 5.88805\n",
      "[6700]\ttraining's rmse: 2.94108\tvalid_1's rmse: 5.88759\n",
      "[6750]\ttraining's rmse: 2.92925\tvalid_1's rmse: 5.8867\n",
      "[6800]\ttraining's rmse: 2.91823\tvalid_1's rmse: 5.88552\n",
      "[6850]\ttraining's rmse: 2.90727\tvalid_1's rmse: 5.88487\n",
      "[6900]\ttraining's rmse: 2.89638\tvalid_1's rmse: 5.88476\n",
      "[6950]\ttraining's rmse: 2.88588\tvalid_1's rmse: 5.88473\n",
      "[7000]\ttraining's rmse: 2.87483\tvalid_1's rmse: 5.88421\n",
      "[7050]\ttraining's rmse: 2.86426\tvalid_1's rmse: 5.8824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7100]\ttraining's rmse: 2.85368\tvalid_1's rmse: 5.88202\n",
      "[7150]\ttraining's rmse: 2.84311\tvalid_1's rmse: 5.88091\n",
      "[7200]\ttraining's rmse: 2.83382\tvalid_1's rmse: 5.8808\n",
      "[7250]\ttraining's rmse: 2.82374\tvalid_1's rmse: 5.87976\n",
      "[7300]\ttraining's rmse: 2.81375\tvalid_1's rmse: 5.8796\n",
      "[7350]\ttraining's rmse: 2.80395\tvalid_1's rmse: 5.87891\n",
      "[7400]\ttraining's rmse: 2.79406\tvalid_1's rmse: 5.87882\n",
      "[7450]\ttraining's rmse: 2.78456\tvalid_1's rmse: 5.87784\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7500]\ttraining's rmse: 2.77543\tvalid_1's rmse: 5.87753\n",
      "[7550]\ttraining's rmse: 2.76585\tvalid_1's rmse: 5.87756\n",
      "[7600]\ttraining's rmse: 2.75649\tvalid_1's rmse: 5.8778\n",
      "[7650]\ttraining's rmse: 2.74746\tvalid_1's rmse: 5.8765\n",
      "[7700]\ttraining's rmse: 2.73781\tvalid_1's rmse: 5.87578\n",
      "[7750]\ttraining's rmse: 2.72837\tvalid_1's rmse: 5.87562\n",
      "[7800]\ttraining's rmse: 2.71935\tvalid_1's rmse: 5.87517\n",
      "[7850]\ttraining's rmse: 2.71044\tvalid_1's rmse: 5.8759\n",
      "[7900]\ttraining's rmse: 2.70142\tvalid_1's rmse: 5.87583\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7950]\ttraining's rmse: 2.69258\tvalid_1's rmse: 5.87468\n",
      "[8000]\ttraining's rmse: 2.68339\tvalid_1's rmse: 5.87403\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[8000]\ttraining's rmse: 2.68339\tvalid_1's rmse: 5.87403\n",
      "Train RMSE: 2.6833920389350823        Valida RMSE: 5.874028408009299\n",
      "Columns: ['emb_714', 'emb_432', 'emb_139', 'emb_587', 'emb_306', 'emb_321', 'emb_433', 'emb_45', 'emb_511', 'emb_168', 'emb_156', 'emb_177', 'emb_151', 'emb_600', 'emb_162', 'emb_295', 'emb_318', 'emb_326', 'emb_249', 'emb_583', 'emb_328', 'emb_29', 'emb_649', 'emb_665', 'emb_69', 'emb_580', 'emb_598', 'emb_495', 'emb_647', 'emb_554', 'emb_485', 'emb_541', 'emb_348', 'emb_675', 'emb_264', 'emb_193', 'emb_115', 'emb_64', 'diff_t', 'emb_288', 'emb_72', 'emb_155', 'emb_585', 'emb_59', 'emb_100', 'emb_97', 'emb_722', 'emb_88', 'emb_104', 'emb_559', 'emb_3', 'emb_429', 'emb_142', 'emb_407', 'emb_467', 'emb_451', 'emb_682', 'emb_522', 'emb_292', 'emb_458', 'emb_687', 'emb_444', 'emb_691', 'emb_514', 'emb_277', 'emb_323', 'emb_693', 'emb_241', 'emb_255', 'emb_91', 'emb_362', 'emb_82', 'emb_297', 'emb_259', 'emb_582', 'emb_99', 'emb_285', 'emb_570', 'emb_41', 'emb_105', 'emb_409', 'emb_445', 'emb_534', 'emb_110', 'emb_557', 'emb_388', 'emb_669', 'emb_590', 'emb_305', 'emb_86', 'emb_159', 'emb_525', 'emb_55', 'emb_50', 'emb_172', 'emb_279', 'emb_335', 'emb_133', 'emb_480', 'emb_537', 'emb_761', 'emb_767', 'emb_468', 'emb_494', 'emb_185', 'emb_401', 'emb_196', 'emb_353', 'emb_147', 'emb_561', 'emb_28', 'emb_596', 'emb_642', 'emb_599', 'emb_273', 'emb_271', 'emb_204', 'emb_607', 'emb_686', 'emb_616', 'emb_322', 'emb_230', 'emb_32', 'emb_556', 'emb_571', 'emb_361', 'emb_472', 'emb_276', 'emb_80', 'emb_446', 'emb_613', 'emb_762', 'emb_73', 'emb_562', 'emb_512', 'emb_548', 'emb_754', 'emb_194', 'emb_203', 'emb_332', 'emb_360', 'emb_415', 'emb_449', 'emb_560', 'emb_725', 'emb_157', 'emb_357', 'emb_400', 'emb_78', 'emb_572', 'emb_720', 'emb_688', 'emb_152', 'emb_439', 'emb_431', 'emb_57', 'emb_174', 'emb_158', 'emb_132', 'emb_66', 'emb_421', 'emb_763', 'emb_533', 'emb_459', 'emb_315', 'emb_12', 'emb_207', 'emb_317', 'emb_694', 'emb_56', 'emb_27', 'emb_68', 'emb_236', 'emb_130', 'emb_486', 'emb_527', 'emb_447', 'emb_251', 'emb_394', 'emb_452', 'emb_161', 'emb_503', 'emb_709', 'emb_416', 'emb_617', 'emb_681', 'emb_87', 'emb_742', 'emb_54', 'emb_414', 'emb_77', 'emb_146', 'emb_330', 'emb_635', 'emb_626', 'emb_84', 'emb_46', 'emb_354', 'emb_736', 'emb_118', 'emb_650', 'emb_532', 'emb_113', 'emb_475', 'emb_111', 'emb_364', 'emb_597', 'emb_622', 'emb_419', 'emb_717', 'emb_378', 'emb_192', 'emb_180', 'emb_555', 'emb_536', 'emb_623', 'emb_610', 'emb_413', 'emb_540', 'emb_674', 'emb_282', 'emb_643', 'emb_49', 'emb_748', 'emb_589', 'emb_187', 'emb_405', 'emb_499', 'emb_520', 'emb_44', 'emb_186', 'emb_546', 'emb_320', 'emb_746', 'emb_417', 'emb_201', 'emb_181', 'emb_516', 'emb_487', 'emb_558', 'emb_462', 'emb_191', 'emb_43', 'emb_202', 'emb_379', 'emb_76', 'emb_695', 'emb_275', 'emb_428', 'emb_165', 'emb_52', 'emb_23', 'emb_741', 'emb_237', 'emb_531', 'emb_175', 'emb_493', 'emb_471', 'emb_263', 'emb_550', 'emb_641', 'emb_340', 'emb_74', 'emb_344', 'emb_545', 'emb_2', 'emb_655', 'emb_257', 'emb_621', 'emb_327', 'emb_129', 'emb_718', 'emb_539', 'emb_666', 'emb_603', 'emb_112', 'emb_689', 'emb_606', 'emb_258', 'emb_301', 'emb_406', 'emb_604', 'emb_198', 'emb_591', 'emb_667', 'emb_355', 'emb_210', 'emb_140', 'emb_40', 'emb_373', 'emb_171', 'emb_309', 'emb_465', 'emb_543', 'emb_579', 'emb_584', 'emb_602', 'emb_544', 'emb_31', 'emb_569', 'emb_628', 'emb_424', 'emb_497', 'emb_437', 'emb_36', 'emb_254', 'emb_169', 'emb_154', 'emb_656', 'emb_338', 'emb_103', 'emb_398', 'emb_94', 'emb_566', 'emb_116', 'emb_238', 'emb_538', 'emb_753', 'emb_586', 'emb_34', 'emb_299', 'emb_9', 'emb_120', 'emb_712', 'emb_477', 'emb_303', 'emb_261', 'emb_455', 'emb_269', 'emb_163', 'emb_510', 'emb_418', 'emb_713', 'emb_500', 'emb_719', 'emb_744', 'ingredients_that_may_be_from_palm_oil_n', 'emb_611', 'emb_233', 'emb_408', 'emb_508', 'emb_731', 'emb_244', 'emb_221', 'emb_574', 'emb_102', 'emb_359', 'emb_95', 'emb_456', 'emb_425', 'emb_266', 'emb_294', 'emb_213', 'emb_399', 'emb_26', 'ingredients_from_palm_oil_n', 'emb_38', 'emb_716', 'emb_126', 'emb_206', 'emb_96', 'emb_135', 'emb_60', 'emb_235', 'emb_690', 'emb_33', 'emb_482', 'emb_392', 'emb_197', 'emb_345', 'emb_470', 'emb_247', 'emb_481', 'emb_4', 'emb_170', 'emb_15', 'emb_551', 'emb_123', 'emb_179', 'emb_624', 'emb_680', 'emb_128', 'emb_658', 'emb_250', 'emb_594', 'emb_521', 'emb_92', 'emb_483', 'emb_324', 'emb_149', 'emb_685', 'emb_200', 'emb_18', 'emb_389', 'emb_648', 'emb_612', 'emb_199', 'emb_374', 'emb_220', 'emb_625', 'emb_670', 'emb_751', 'emb_268', 'emb_308', 'emb_496', 'emb_387', 'emb_371', 'emb_339', 'emb_509', 'emb_438', 'emb_58', 'emb_61', 'emb_98', 'emb_565', 'emb_668', 'emb_404', 'emb_676', 'emb_307', 'emb_274', 'emb_764', 'emb_765', 'emb_37', 'emb_283', 'emb_83', 'emb_661', 'emb_747', 'emb_476', 'emb_316', 'emb_578', 'emb_11', 'emb_724', 'emb_402', 'emb_646', 'emb_260', 'emb_121', 'emb_298', 'emb_253', 'emb_410', 'emb_653', 'emb_239', 'emb_601', 'emb_662', 'emb_701', 'emb_153', 'emb_107', 'emb_85', 'emb_160', 'emb_517', 'emb_302', 'emb_632', 'emb_350', 'emb_188', 'emb_265', 'emb_311', 'emb_334', 'emb_51', 'emb_705', 'emb_683', 'emb_563', 'emb_535', 'emb_383', 'emb_217', 'emb_434', 'emb_526', 'emb_502', 'emb_501', 'emb_491', 'emb_138', 'emb_397', 'emb_310', 'emb_728', 'emb_234', 'emb_492', 'emb_20', 'emb_479', 'emb_367', 'emb_79', 'emb_524', 'emb_281', 'emb_341', 'emb_403', 'emb_6', 'emb_270', 'emb_141', 'emb_342', 'emb_506', 'emb_678', 'emb_654', 'emb_42', 'emb_343', 'emb_53', 'emb_750', 'emb_457', 'emb_638', 'emb_507', 'emb_150', 'emb_664', 'emb_660', 'emb_365', 'emb_393', 'emb_166', 'emb_289', 'emb_395', 'emb_730', 'emb_347', 'emb_464', 'emb_125', 'emb_707', 'emb_697', 'emb_376', 'emb_759', 'emb_290', 'emb_216', 'emb_671', 'emb_24', 'emb_618', 'emb_119', 'emb_35', 'emb_651', 'emb_14', 'emb_679', 'emb_659', 'emb_745', 'emb_48', 'emb_518', 'emb_450', 'emb_21', 'emb_93', 'emb_757', 'emb_463', 'emb_240', 'emb_164', 'emb_319', 'emb_325', 'emb_699', 'emb_605', 'emb_0', 'emb_22', 'emb_351', 'emb_183', 'emb_243', 'emb_256', 'emb_313', 'emb_189', 'emb_489', 'emb_564', 'emb_644', 'emb_528', 'emb_304', 'emb_692', 'emb_633', 'emb_443', 'emb_368', 'additives_n', 'emb_608', 'emb_504', 'emb_749', 'emb_229', 'emb_65', 'emb_331', 'emb_286', 'emb_702', 'emb_677', 'emb_453', 'emb_287', 'emb_71', 'emb_127', 'emb_90', 'emb_755', 'emb_176', 'emb_214', 'emb_639', 'emb_756', 'emb_484', 'emb_490', 'emb_114', 'emb_549', 'emb_454', 'emb_391', 'emb_637', 'emb_67', 'emb_291', 'emb_228', 'emb_478', 'emb_513', 'emb_629', 'emb_333', 'emb_346', 'emb_377', 'emb_440', 'emb_634', 'emb_684', 'emb_25', 'emb_735', 'emb_708', 'emb_696', 'emb_766', 'emb_101', 'emb_529', 'emb_16', 'emb_498', 'emb_734', 'emb_620', 'emb_448', 'emb_715', 'emb_381', 'emb_743', 'emb_252', 'emb_108', 'emb_293', 'emb_427', 'emb_136', 'emb_614', 'emb_473', 'emb_208', 'emb_469', 'emb_219', 'emb_117', 'emb_173', 'emb_519', 'emb_337', 'emb_356', 'emb_657', 'emb_627', 'emb_1', 'emb_222', 'emb_272', 'emb_706', 'emb_442', 'emb_144', 'emb_758', 'emb_225', 'emb_435', 'emb_384', 'emb_673', 'emb_411', 'emb_738', 'emb_593', 'emb_215', 'emb_218', 'emb_420', 'emb_430', 'emb_576', 'emb_205', 'emb_703', 'emb_62', 'emb_227', 'emb_167', 'emb_212', 'emb_134', 'emb_575', 'emb_145', 'emb_39', 'emb_231', 'emb_312', 'emb_567', 'emb_143', 'emb_314', 'emb_542', 'emb_573', 'emb_436', 'emb_547', 'emb_422', 'emb_733', 'emb_248', 'emb_737', 'emb_466', 'emb_278', 'emb_426', 'emb_137', 'emb_592', 'emb_386', 'emb_284', 'emb_246', 'emb_523', 'emb_8', 'emb_710', 'emb_122', 'emb_5', 'emb_296', 'emb_396', 'emb_17', 'emb_267', 'emb_505', 'emb_7', 'emb_698', 'emb_385', 'emb_19', 'emb_672', 'emb_636', 'emb_148', 'emb_577', 'emb_723', 'emb_652', 'emb_595', 'emb_369', 'emb_124', 'emb_640', 'emb_630', 'emb_47', 'emb_721', 'emb_375', 'emb_700', 'emb_224', 'emb_358', 'emb_349', 'emb_581', 'emb_530', 'emb_280', 'emb_631', 'emb_740', 'emb_10', 'emb_382', 'emb_232', 'emb_75', 'emb_195', 'emb_732', 'emb_619', 'emb_226', 'emb_615', 'emb_81', 'emb_423', 'emb_663', 'emb_131', 'emb_461', 'emb_729', 'emb_209', 'emb_352', 'emb_262', 'emb_366', 'emb_727', 'emb_300', 'emb_711', 'emb_370', 'emb_515', 'emb_30', 'emb_363', 'emb_553', 'emb_441', 'emb_223', 'emb_739', 'emb_609', 'emb_726', 'emb_372', 'emb_390', 'emb_412', 'emb_645', 'emb_190', 'emb_63', 'emb_752', 'emb_178', 'emb_380', 'emb_106', 'emb_336', 'emb_760', 'emb_460', 'emb_329', 'emb_70', 'emb_588', 'emb_474', 'emb_704', 'emb_211', 'emb_568', 'emb_89', 'emb_184', 'emb_182', 'emb_109', 'emb_245', 'emb_552', 'emb_242', 'emb_13', 'emb_488', 'label_states_en_brands', 'label_states_en_categories', 'label_states_en_characteristics', 'label_states_en_expiration date', 'label_states_en_general_complete', 'label_states_en_ingredients', 'label_pnns_groups_1', 'label_pnns_groups_2', 'label_states_en_packaging', 'label_states_en_packaging-code-', 'label_states_en_photo_upload', 'label_states_en_photo_validate', 'label_states_en_product name', 'label_states_en_quantity']\n",
      "Cat index: [772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785]\n",
      "---------- Training fold NÂº 4 ----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 196221\n",
      "[LightGBM] [Info] Number of data points in the train set: 81623, number of used features: 786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.170344\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's rmse: 7.14322\tvalid_1's rmse: 7.21582\n",
      "[100]\ttraining's rmse: 6.82372\tvalid_1's rmse: 6.9549\n",
      "[150]\ttraining's rmse: 6.63726\tvalid_1's rmse: 6.82102\n",
      "[200]\ttraining's rmse: 6.4998\tvalid_1's rmse: 6.73171\n",
      "[250]\ttraining's rmse: 6.38862\tvalid_1's rmse: 6.66664\n",
      "[300]\ttraining's rmse: 6.2924\tvalid_1's rmse: 6.62009\n",
      "[350]\ttraining's rmse: 6.20667\tvalid_1's rmse: 6.57454\n",
      "[400]\ttraining's rmse: 6.12872\tvalid_1's rmse: 6.53721\n",
      "[450]\ttraining's rmse: 6.05685\tvalid_1's rmse: 6.50609\n",
      "[500]\ttraining's rmse: 5.98803\tvalid_1's rmse: 6.47827\n",
      "[550]\ttraining's rmse: 5.92074\tvalid_1's rmse: 6.44804\n",
      "[600]\ttraining's rmse: 5.85986\tvalid_1's rmse: 6.42755\n",
      "[650]\ttraining's rmse: 5.79921\tvalid_1's rmse: 6.40353\n",
      "[700]\ttraining's rmse: 5.74222\tvalid_1's rmse: 6.38549\n",
      "[750]\ttraining's rmse: 5.68775\tvalid_1's rmse: 6.36416\n",
      "[800]\ttraining's rmse: 5.63764\tvalid_1's rmse: 6.34903\n",
      "[850]\ttraining's rmse: 5.58581\tvalid_1's rmse: 6.33305\n",
      "[900]\ttraining's rmse: 5.53708\tvalid_1's rmse: 6.31941\n",
      "[950]\ttraining's rmse: 5.48929\tvalid_1's rmse: 6.3041\n",
      "[1000]\ttraining's rmse: 5.44291\tvalid_1's rmse: 6.29049\n",
      "[1050]\ttraining's rmse: 5.39792\tvalid_1's rmse: 6.27834\n",
      "[1100]\ttraining's rmse: 5.35402\tvalid_1's rmse: 6.26761\n",
      "[1150]\ttraining's rmse: 5.31035\tvalid_1's rmse: 6.25729\n",
      "[1200]\ttraining's rmse: 5.26759\tvalid_1's rmse: 6.24578\n",
      "[1250]\ttraining's rmse: 5.22664\tvalid_1's rmse: 6.23677\n",
      "[1300]\ttraining's rmse: 5.18637\tvalid_1's rmse: 6.22839\n",
      "[1350]\ttraining's rmse: 5.14642\tvalid_1's rmse: 6.21853\n",
      "[1400]\ttraining's rmse: 5.10706\tvalid_1's rmse: 6.20846\n",
      "[1450]\ttraining's rmse: 5.07093\tvalid_1's rmse: 6.20006\n",
      "[1500]\ttraining's rmse: 5.03377\tvalid_1's rmse: 6.19269\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1550]\ttraining's rmse: 4.99689\tvalid_1's rmse: 6.18384\n",
      "[1600]\ttraining's rmse: 4.96138\tvalid_1's rmse: 6.17486\n",
      "[1650]\ttraining's rmse: 4.92716\tvalid_1's rmse: 6.1649\n",
      "[1700]\ttraining's rmse: 4.89405\tvalid_1's rmse: 6.15994\n",
      "[1750]\ttraining's rmse: 4.86057\tvalid_1's rmse: 6.15384\n",
      "[1800]\ttraining's rmse: 4.82624\tvalid_1's rmse: 6.14752\n",
      "[1850]\ttraining's rmse: 4.79228\tvalid_1's rmse: 6.14096\n",
      "[1900]\ttraining's rmse: 4.75989\tvalid_1's rmse: 6.13526\n",
      "[1950]\ttraining's rmse: 4.72867\tvalid_1's rmse: 6.12846\n",
      "[2000]\ttraining's rmse: 4.69708\tvalid_1's rmse: 6.12075\n",
      "[2050]\ttraining's rmse: 4.66592\tvalid_1's rmse: 6.11538\n",
      "[2100]\ttraining's rmse: 4.63575\tvalid_1's rmse: 6.11155\n",
      "[2150]\ttraining's rmse: 4.6052\tvalid_1's rmse: 6.10789\n",
      "[2200]\ttraining's rmse: 4.57618\tvalid_1's rmse: 6.10443\n",
      "[2250]\ttraining's rmse: 4.54687\tvalid_1's rmse: 6.10027\n",
      "[2300]\ttraining's rmse: 4.51703\tvalid_1's rmse: 6.09521\n",
      "[2350]\ttraining's rmse: 4.48899\tvalid_1's rmse: 6.09269\n",
      "[2400]\ttraining's rmse: 4.46182\tvalid_1's rmse: 6.08793\n",
      "[2450]\ttraining's rmse: 4.43493\tvalid_1's rmse: 6.08428\n",
      "[2500]\ttraining's rmse: 4.40758\tvalid_1's rmse: 6.08242\n",
      "[2550]\ttraining's rmse: 4.37975\tvalid_1's rmse: 6.08008\n",
      "[2600]\ttraining's rmse: 4.3529\tvalid_1's rmse: 6.07509\n",
      "[2650]\ttraining's rmse: 4.32696\tvalid_1's rmse: 6.07115\n",
      "[2700]\ttraining's rmse: 4.30202\tvalid_1's rmse: 6.06782\n",
      "[2750]\ttraining's rmse: 4.27799\tvalid_1's rmse: 6.06664\n",
      "[2800]\ttraining's rmse: 4.25322\tvalid_1's rmse: 6.06334\n",
      "[2850]\ttraining's rmse: 4.22891\tvalid_1's rmse: 6.05843\n",
      "[2900]\ttraining's rmse: 4.20463\tvalid_1's rmse: 6.05452\n",
      "[2950]\ttraining's rmse: 4.1809\tvalid_1's rmse: 6.05264\n",
      "[3000]\ttraining's rmse: 4.15734\tvalid_1's rmse: 6.04946\n",
      "[3050]\ttraining's rmse: 4.13337\tvalid_1's rmse: 6.04549\n",
      "[3100]\ttraining's rmse: 4.11029\tvalid_1's rmse: 6.04242\n",
      "[3150]\ttraining's rmse: 4.08734\tvalid_1's rmse: 6.04085\n",
      "[3200]\ttraining's rmse: 4.06466\tvalid_1's rmse: 6.03738\n",
      "[3250]\ttraining's rmse: 4.04199\tvalid_1's rmse: 6.03341\n",
      "[3300]\ttraining's rmse: 4.01941\tvalid_1's rmse: 6.02895\n",
      "[3350]\ttraining's rmse: 3.99713\tvalid_1's rmse: 6.02516\n",
      "[3400]\ttraining's rmse: 3.97504\tvalid_1's rmse: 6.02107\n",
      "[3450]\ttraining's rmse: 3.95389\tvalid_1's rmse: 6.01979\n",
      "[3500]\ttraining's rmse: 3.9331\tvalid_1's rmse: 6.01746\n",
      "[3550]\ttraining's rmse: 3.91274\tvalid_1's rmse: 6.01461\n",
      "[3600]\ttraining's rmse: 3.89199\tvalid_1's rmse: 6.01277\n",
      "[3650]\ttraining's rmse: 3.87208\tvalid_1's rmse: 6.01217\n",
      "[3700]\ttraining's rmse: 3.85167\tvalid_1's rmse: 6.00993\n",
      "[3750]\ttraining's rmse: 3.8317\tvalid_1's rmse: 6.00815\n",
      "[3800]\ttraining's rmse: 3.81162\tvalid_1's rmse: 6.0069\n",
      "[3850]\ttraining's rmse: 3.7918\tvalid_1's rmse: 6.00483\n",
      "[3900]\ttraining's rmse: 3.77243\tvalid_1's rmse: 6.00093\n",
      "[3950]\ttraining's rmse: 3.75372\tvalid_1's rmse: 6.00016\n",
      "[4000]\ttraining's rmse: 3.73545\tvalid_1's rmse: 5.99805\n",
      "[4050]\ttraining's rmse: 3.71613\tvalid_1's rmse: 5.99597\n",
      "[4100]\ttraining's rmse: 3.69757\tvalid_1's rmse: 5.99537\n",
      "[4150]\ttraining's rmse: 3.67833\tvalid_1's rmse: 5.99319\n",
      "[4200]\ttraining's rmse: 3.66\tvalid_1's rmse: 5.99184\n",
      "[4250]\ttraining's rmse: 3.64141\tvalid_1's rmse: 5.99052\n",
      "[4300]\ttraining's rmse: 3.62383\tvalid_1's rmse: 5.98726\n",
      "[4350]\ttraining's rmse: 3.60578\tvalid_1's rmse: 5.98579\n",
      "[4400]\ttraining's rmse: 3.58861\tvalid_1's rmse: 5.98438\n",
      "[4450]\ttraining's rmse: 3.57166\tvalid_1's rmse: 5.98284\n",
      "[4500]\ttraining's rmse: 3.55393\tvalid_1's rmse: 5.98176\n",
      "[4550]\ttraining's rmse: 3.53709\tvalid_1's rmse: 5.98028\n",
      "[4600]\ttraining's rmse: 3.52021\tvalid_1's rmse: 5.98032\n",
      "[4650]\ttraining's rmse: 3.50448\tvalid_1's rmse: 5.97965\n",
      "[4700]\ttraining's rmse: 3.48787\tvalid_1's rmse: 5.97915\n",
      "[4750]\ttraining's rmse: 3.47114\tvalid_1's rmse: 5.97809\n",
      "[4800]\ttraining's rmse: 3.45525\tvalid_1's rmse: 5.977\n",
      "[4850]\ttraining's rmse: 3.43977\tvalid_1's rmse: 5.97533\n",
      "[4900]\ttraining's rmse: 3.42349\tvalid_1's rmse: 5.97478\n",
      "[4950]\ttraining's rmse: 3.40774\tvalid_1's rmse: 5.9733\n",
      "[5000]\ttraining's rmse: 3.39148\tvalid_1's rmse: 5.97308\n",
      "[5050]\ttraining's rmse: 3.37636\tvalid_1's rmse: 5.97125\n",
      "[5100]\ttraining's rmse: 3.36147\tvalid_1's rmse: 5.9698\n",
      "[5150]\ttraining's rmse: 3.34645\tvalid_1's rmse: 5.96824\n",
      "[5200]\ttraining's rmse: 3.33144\tvalid_1's rmse: 5.96743\n",
      "[5250]\ttraining's rmse: 3.31653\tvalid_1's rmse: 5.96731\n",
      "[5300]\ttraining's rmse: 3.30243\tvalid_1's rmse: 5.96576\n",
      "[5350]\ttraining's rmse: 3.28754\tvalid_1's rmse: 5.96377\n",
      "[5400]\ttraining's rmse: 3.27325\tvalid_1's rmse: 5.96223\n",
      "[5450]\ttraining's rmse: 3.25985\tvalid_1's rmse: 5.96234\n",
      "[5500]\ttraining's rmse: 3.24573\tvalid_1's rmse: 5.96225\n",
      "[5550]\ttraining's rmse: 3.23226\tvalid_1's rmse: 5.96175\n",
      "[5600]\ttraining's rmse: 3.21818\tvalid_1's rmse: 5.9608\n",
      "[5650]\ttraining's rmse: 3.20496\tvalid_1's rmse: 5.9588\n",
      "[5700]\ttraining's rmse: 3.19173\tvalid_1's rmse: 5.95727\n",
      "[5750]\ttraining's rmse: 3.1784\tvalid_1's rmse: 5.95638\n",
      "[5800]\ttraining's rmse: 3.16503\tvalid_1's rmse: 5.95574\n",
      "[5850]\ttraining's rmse: 3.15149\tvalid_1's rmse: 5.95498\n",
      "[5900]\ttraining's rmse: 3.13859\tvalid_1's rmse: 5.95409\n",
      "[5950]\ttraining's rmse: 3.12579\tvalid_1's rmse: 5.95338\n",
      "[6000]\ttraining's rmse: 3.11323\tvalid_1's rmse: 5.95395\n",
      "[6050]\ttraining's rmse: 3.10042\tvalid_1's rmse: 5.95279\n",
      "[6100]\ttraining's rmse: 3.08812\tvalid_1's rmse: 5.95166\n",
      "[6150]\ttraining's rmse: 3.075\tvalid_1's rmse: 5.95128\n",
      "[6200]\ttraining's rmse: 3.06248\tvalid_1's rmse: 5.95085\n",
      "[6250]\ttraining's rmse: 3.05071\tvalid_1's rmse: 5.95037\n",
      "[6300]\ttraining's rmse: 3.03875\tvalid_1's rmse: 5.95044\n",
      "[6350]\ttraining's rmse: 3.02667\tvalid_1's rmse: 5.94987\n",
      "[6400]\ttraining's rmse: 3.01554\tvalid_1's rmse: 5.94858\n",
      "[6450]\ttraining's rmse: 3.00396\tvalid_1's rmse: 5.94852\n",
      "[6500]\ttraining's rmse: 2.99241\tvalid_1's rmse: 5.94804\n",
      "[6550]\ttraining's rmse: 2.9807\tvalid_1's rmse: 5.94695\n",
      "[6600]\ttraining's rmse: 2.96912\tvalid_1's rmse: 5.9471\n",
      "[6650]\ttraining's rmse: 2.95751\tvalid_1's rmse: 5.9463\n",
      "[6700]\ttraining's rmse: 2.9462\tvalid_1's rmse: 5.94531\n",
      "[6750]\ttraining's rmse: 2.93481\tvalid_1's rmse: 5.94534\n",
      "[6800]\ttraining's rmse: 2.9239\tvalid_1's rmse: 5.94443\n",
      "[6850]\ttraining's rmse: 2.91262\tvalid_1's rmse: 5.94345\n",
      "[6900]\ttraining's rmse: 2.90197\tvalid_1's rmse: 5.94299\n",
      "[6950]\ttraining's rmse: 2.89145\tvalid_1's rmse: 5.94246\n",
      "[7000]\ttraining's rmse: 2.88078\tvalid_1's rmse: 5.9412\n",
      "[7050]\ttraining's rmse: 2.86985\tvalid_1's rmse: 5.93998\n",
      "[7100]\ttraining's rmse: 2.85939\tvalid_1's rmse: 5.94031\n",
      "[7150]\ttraining's rmse: 2.84935\tvalid_1's rmse: 5.93973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7200]\ttraining's rmse: 2.83871\tvalid_1's rmse: 5.9385\n",
      "[7250]\ttraining's rmse: 2.82808\tvalid_1's rmse: 5.93804\n",
      "[7300]\ttraining's rmse: 2.81794\tvalid_1's rmse: 5.93809\n",
      "[7350]\ttraining's rmse: 2.80801\tvalid_1's rmse: 5.9376\n",
      "[7400]\ttraining's rmse: 2.798\tvalid_1's rmse: 5.93683\n",
      "[7450]\ttraining's rmse: 2.78885\tvalid_1's rmse: 5.93717\n",
      "[7500]\ttraining's rmse: 2.77914\tvalid_1's rmse: 5.93693\n",
      "[7550]\ttraining's rmse: 2.76938\tvalid_1's rmse: 5.93584\n",
      "[7600]\ttraining's rmse: 2.75992\tvalid_1's rmse: 5.93573\n",
      "[7650]\ttraining's rmse: 2.75102\tvalid_1's rmse: 5.93565\n",
      "[7700]\ttraining's rmse: 2.74215\tvalid_1's rmse: 5.93502\n",
      "[7750]\ttraining's rmse: 2.7332\tvalid_1's rmse: 5.93446\n",
      "[7800]\ttraining's rmse: 2.72379\tvalid_1's rmse: 5.934\n",
      "[7850]\ttraining's rmse: 2.71471\tvalid_1's rmse: 5.9334\n",
      "[7900]\ttraining's rmse: 2.70572\tvalid_1's rmse: 5.93296\n",
      "[7950]\ttraining's rmse: 2.69735\tvalid_1's rmse: 5.93173\n",
      "[8000]\ttraining's rmse: 2.68854\tvalid_1's rmse: 5.93156\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[8000]\ttraining's rmse: 2.68854\tvalid_1's rmse: 5.93156\n",
      "Train RMSE: 2.6885383034429453        Valida RMSE: 5.931560843467246\n",
      "Columns: ['emb_714', 'emb_432', 'emb_139', 'emb_587', 'emb_306', 'emb_321', 'emb_433', 'emb_45', 'emb_511', 'emb_168', 'emb_156', 'emb_177', 'emb_151', 'emb_600', 'emb_162', 'emb_295', 'emb_318', 'emb_326', 'emb_249', 'emb_583', 'emb_328', 'emb_29', 'emb_649', 'emb_665', 'emb_69', 'emb_580', 'emb_598', 'emb_495', 'emb_647', 'emb_554', 'emb_485', 'emb_541', 'emb_348', 'emb_675', 'emb_264', 'emb_193', 'emb_115', 'emb_64', 'diff_t', 'emb_288', 'emb_72', 'emb_155', 'emb_585', 'emb_59', 'emb_100', 'emb_97', 'emb_722', 'emb_88', 'emb_104', 'emb_559', 'emb_3', 'emb_429', 'emb_142', 'emb_407', 'emb_467', 'emb_451', 'emb_682', 'emb_522', 'emb_292', 'emb_458', 'emb_687', 'emb_444', 'emb_691', 'emb_514', 'emb_277', 'emb_323', 'emb_693', 'emb_241', 'emb_255', 'emb_91', 'emb_362', 'emb_82', 'emb_297', 'emb_259', 'emb_582', 'emb_99', 'emb_285', 'emb_570', 'emb_41', 'emb_105', 'emb_409', 'emb_445', 'emb_534', 'emb_110', 'emb_557', 'emb_388', 'emb_669', 'emb_590', 'emb_305', 'emb_86', 'emb_159', 'emb_525', 'emb_55', 'emb_50', 'emb_172', 'emb_279', 'emb_335', 'emb_133', 'emb_480', 'emb_537', 'emb_761', 'emb_767', 'emb_468', 'emb_494', 'emb_185', 'emb_401', 'emb_196', 'emb_353', 'emb_147', 'emb_561', 'emb_28', 'emb_596', 'emb_642', 'emb_599', 'emb_273', 'emb_271', 'emb_204', 'emb_607', 'emb_686', 'emb_616', 'emb_322', 'emb_230', 'emb_32', 'emb_556', 'emb_571', 'emb_361', 'emb_472', 'emb_276', 'emb_80', 'emb_446', 'emb_613', 'emb_762', 'emb_73', 'emb_562', 'emb_512', 'emb_548', 'emb_754', 'emb_194', 'emb_203', 'emb_332', 'emb_360', 'emb_415', 'emb_449', 'emb_560', 'emb_725', 'emb_157', 'emb_357', 'emb_400', 'emb_78', 'emb_572', 'emb_720', 'emb_688', 'emb_152', 'emb_439', 'emb_431', 'emb_57', 'emb_174', 'emb_158', 'emb_132', 'emb_66', 'emb_421', 'emb_763', 'emb_533', 'emb_459', 'emb_315', 'emb_12', 'emb_207', 'emb_317', 'emb_694', 'emb_56', 'emb_27', 'emb_68', 'emb_236', 'emb_130', 'emb_486', 'emb_527', 'emb_447', 'emb_251', 'emb_394', 'emb_452', 'emb_161', 'emb_503', 'emb_709', 'emb_416', 'emb_617', 'emb_681', 'emb_87', 'emb_742', 'emb_54', 'emb_414', 'emb_77', 'emb_146', 'emb_330', 'emb_635', 'emb_626', 'emb_84', 'emb_46', 'emb_354', 'emb_736', 'emb_118', 'emb_650', 'emb_532', 'emb_113', 'emb_475', 'emb_111', 'emb_364', 'emb_597', 'emb_622', 'emb_419', 'emb_717', 'emb_378', 'emb_192', 'emb_180', 'emb_555', 'emb_536', 'emb_623', 'emb_610', 'emb_413', 'emb_540', 'emb_674', 'emb_282', 'emb_643', 'emb_49', 'emb_748', 'emb_589', 'emb_187', 'emb_405', 'emb_499', 'emb_520', 'emb_44', 'emb_186', 'emb_546', 'emb_320', 'emb_746', 'emb_417', 'emb_201', 'emb_181', 'emb_516', 'emb_487', 'emb_558', 'emb_462', 'emb_191', 'emb_43', 'emb_202', 'emb_379', 'emb_76', 'emb_695', 'emb_275', 'emb_428', 'emb_165', 'emb_52', 'emb_23', 'emb_741', 'emb_237', 'emb_531', 'emb_175', 'emb_493', 'emb_471', 'emb_263', 'emb_550', 'emb_641', 'emb_340', 'emb_74', 'emb_344', 'emb_545', 'emb_2', 'emb_655', 'emb_257', 'emb_621', 'emb_327', 'emb_129', 'emb_718', 'emb_539', 'emb_666', 'emb_603', 'emb_112', 'emb_689', 'emb_606', 'emb_258', 'emb_301', 'emb_406', 'emb_604', 'emb_198', 'emb_591', 'emb_667', 'emb_355', 'emb_210', 'emb_140', 'emb_40', 'emb_373', 'emb_171', 'emb_309', 'emb_465', 'emb_543', 'emb_579', 'emb_584', 'emb_602', 'emb_544', 'emb_31', 'emb_569', 'emb_628', 'emb_424', 'emb_497', 'emb_437', 'emb_36', 'emb_254', 'emb_169', 'emb_154', 'emb_656', 'emb_338', 'emb_103', 'emb_398', 'emb_94', 'emb_566', 'emb_116', 'emb_238', 'emb_538', 'emb_753', 'emb_586', 'emb_34', 'emb_299', 'emb_9', 'emb_120', 'emb_712', 'emb_477', 'emb_303', 'emb_261', 'emb_455', 'emb_269', 'emb_163', 'emb_510', 'emb_418', 'emb_713', 'emb_500', 'emb_719', 'emb_744', 'ingredients_that_may_be_from_palm_oil_n', 'emb_611', 'emb_233', 'emb_408', 'emb_508', 'emb_731', 'emb_244', 'emb_221', 'emb_574', 'emb_102', 'emb_359', 'emb_95', 'emb_456', 'emb_425', 'emb_266', 'emb_294', 'emb_213', 'emb_399', 'emb_26', 'ingredients_from_palm_oil_n', 'emb_38', 'emb_716', 'emb_126', 'emb_206', 'emb_96', 'emb_135', 'emb_60', 'emb_235', 'emb_690', 'emb_33', 'emb_482', 'emb_392', 'emb_197', 'emb_345', 'emb_470', 'emb_247', 'emb_481', 'emb_4', 'emb_170', 'emb_15', 'emb_551', 'emb_123', 'emb_179', 'emb_624', 'emb_680', 'emb_128', 'emb_658', 'emb_250', 'emb_594', 'emb_521', 'emb_92', 'emb_483', 'emb_324', 'emb_149', 'emb_685', 'emb_200', 'emb_18', 'emb_389', 'emb_648', 'emb_612', 'emb_199', 'emb_374', 'emb_220', 'emb_625', 'emb_670', 'emb_751', 'emb_268', 'emb_308', 'emb_496', 'emb_387', 'emb_371', 'emb_339', 'emb_509', 'emb_438', 'emb_58', 'emb_61', 'emb_98', 'emb_565', 'emb_668', 'emb_404', 'emb_676', 'emb_307', 'emb_274', 'emb_764', 'emb_765', 'emb_37', 'emb_283', 'emb_83', 'emb_661', 'emb_747', 'emb_476', 'emb_316', 'emb_578', 'emb_11', 'emb_724', 'emb_402', 'emb_646', 'emb_260', 'emb_121', 'emb_298', 'emb_253', 'emb_410', 'emb_653', 'emb_239', 'emb_601', 'emb_662', 'emb_701', 'emb_153', 'emb_107', 'emb_85', 'emb_160', 'emb_517', 'emb_302', 'emb_632', 'emb_350', 'emb_188', 'emb_265', 'emb_311', 'emb_334', 'emb_51', 'emb_705', 'emb_683', 'emb_563', 'emb_535', 'emb_383', 'emb_217', 'emb_434', 'emb_526', 'emb_502', 'emb_501', 'emb_491', 'emb_138', 'emb_397', 'emb_310', 'emb_728', 'emb_234', 'emb_492', 'emb_20', 'emb_479', 'emb_367', 'emb_79', 'emb_524', 'emb_281', 'emb_341', 'emb_403', 'emb_6', 'emb_270', 'emb_141', 'emb_342', 'emb_506', 'emb_678', 'emb_654', 'emb_42', 'emb_343', 'emb_53', 'emb_750', 'emb_457', 'emb_638', 'emb_507', 'emb_150', 'emb_664', 'emb_660', 'emb_365', 'emb_393', 'emb_166', 'emb_289', 'emb_395', 'emb_730', 'emb_347', 'emb_464', 'emb_125', 'emb_707', 'emb_697', 'emb_376', 'emb_759', 'emb_290', 'emb_216', 'emb_671', 'emb_24', 'emb_618', 'emb_119', 'emb_35', 'emb_651', 'emb_14', 'emb_679', 'emb_659', 'emb_745', 'emb_48', 'emb_518', 'emb_450', 'emb_21', 'emb_93', 'emb_757', 'emb_463', 'emb_240', 'emb_164', 'emb_319', 'emb_325', 'emb_699', 'emb_605', 'emb_0', 'emb_22', 'emb_351', 'emb_183', 'emb_243', 'emb_256', 'emb_313', 'emb_189', 'emb_489', 'emb_564', 'emb_644', 'emb_528', 'emb_304', 'emb_692', 'emb_633', 'emb_443', 'emb_368', 'additives_n', 'emb_608', 'emb_504', 'emb_749', 'emb_229', 'emb_65', 'emb_331', 'emb_286', 'emb_702', 'emb_677', 'emb_453', 'emb_287', 'emb_71', 'emb_127', 'emb_90', 'emb_755', 'emb_176', 'emb_214', 'emb_639', 'emb_756', 'emb_484', 'emb_490', 'emb_114', 'emb_549', 'emb_454', 'emb_391', 'emb_637', 'emb_67', 'emb_291', 'emb_228', 'emb_478', 'emb_513', 'emb_629', 'emb_333', 'emb_346', 'emb_377', 'emb_440', 'emb_634', 'emb_684', 'emb_25', 'emb_735', 'emb_708', 'emb_696', 'emb_766', 'emb_101', 'emb_529', 'emb_16', 'emb_498', 'emb_734', 'emb_620', 'emb_448', 'emb_715', 'emb_381', 'emb_743', 'emb_252', 'emb_108', 'emb_293', 'emb_427', 'emb_136', 'emb_614', 'emb_473', 'emb_208', 'emb_469', 'emb_219', 'emb_117', 'emb_173', 'emb_519', 'emb_337', 'emb_356', 'emb_657', 'emb_627', 'emb_1', 'emb_222', 'emb_272', 'emb_706', 'emb_442', 'emb_144', 'emb_758', 'emb_225', 'emb_435', 'emb_384', 'emb_673', 'emb_411', 'emb_738', 'emb_593', 'emb_215', 'emb_218', 'emb_420', 'emb_430', 'emb_576', 'emb_205', 'emb_703', 'emb_62', 'emb_227', 'emb_167', 'emb_212', 'emb_134', 'emb_575', 'emb_145', 'emb_39', 'emb_231', 'emb_312', 'emb_567', 'emb_143', 'emb_314', 'emb_542', 'emb_573', 'emb_436', 'emb_547', 'emb_422', 'emb_733', 'emb_248', 'emb_737', 'emb_466', 'emb_278', 'emb_426', 'emb_137', 'emb_592', 'emb_386', 'emb_284', 'emb_246', 'emb_523', 'emb_8', 'emb_710', 'emb_122', 'emb_5', 'emb_296', 'emb_396', 'emb_17', 'emb_267', 'emb_505', 'emb_7', 'emb_698', 'emb_385', 'emb_19', 'emb_672', 'emb_636', 'emb_148', 'emb_577', 'emb_723', 'emb_652', 'emb_595', 'emb_369', 'emb_124', 'emb_640', 'emb_630', 'emb_47', 'emb_721', 'emb_375', 'emb_700', 'emb_224', 'emb_358', 'emb_349', 'emb_581', 'emb_530', 'emb_280', 'emb_631', 'emb_740', 'emb_10', 'emb_382', 'emb_232', 'emb_75', 'emb_195', 'emb_732', 'emb_619', 'emb_226', 'emb_615', 'emb_81', 'emb_423', 'emb_663', 'emb_131', 'emb_461', 'emb_729', 'emb_209', 'emb_352', 'emb_262', 'emb_366', 'emb_727', 'emb_300', 'emb_711', 'emb_370', 'emb_515', 'emb_30', 'emb_363', 'emb_553', 'emb_441', 'emb_223', 'emb_739', 'emb_609', 'emb_726', 'emb_372', 'emb_390', 'emb_412', 'emb_645', 'emb_190', 'emb_63', 'emb_752', 'emb_178', 'emb_380', 'emb_106', 'emb_336', 'emb_760', 'emb_460', 'emb_329', 'emb_70', 'emb_588', 'emb_474', 'emb_704', 'emb_211', 'emb_568', 'emb_89', 'emb_184', 'emb_182', 'emb_109', 'emb_245', 'emb_552', 'emb_242', 'emb_13', 'emb_488', 'label_states_en_brands', 'label_states_en_categories', 'label_states_en_characteristics', 'label_states_en_expiration date', 'label_states_en_general_complete', 'label_states_en_ingredients', 'label_pnns_groups_1', 'label_pnns_groups_2', 'label_states_en_packaging', 'label_states_en_packaging-code-', 'label_states_en_photo_upload', 'label_states_en_photo_validate', 'label_states_en_product name', 'label_states_en_quantity']\n",
      "Cat index: [772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785]\n",
      "---------- Training fold NÂº 5 ----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 196221\n",
      "[LightGBM] [Info] Number of data points in the train set: 81623, number of used features: 786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.170246\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's rmse: 7.16241\tvalid_1's rmse: 7.18803\n",
      "[100]\ttraining's rmse: 6.83579\tvalid_1's rmse: 6.91048\n",
      "[150]\ttraining's rmse: 6.6518\tvalid_1's rmse: 6.77142\n",
      "[200]\ttraining's rmse: 6.51427\tvalid_1's rmse: 6.67706\n",
      "[250]\ttraining's rmse: 6.40554\tvalid_1's rmse: 6.61535\n",
      "[300]\ttraining's rmse: 6.30597\tvalid_1's rmse: 6.56082\n",
      "[350]\ttraining's rmse: 6.21958\tvalid_1's rmse: 6.5162\n",
      "[400]\ttraining's rmse: 6.14002\tvalid_1's rmse: 6.4803\n",
      "[450]\ttraining's rmse: 6.06542\tvalid_1's rmse: 6.44491\n",
      "[500]\ttraining's rmse: 5.99462\tvalid_1's rmse: 6.41173\n",
      "[550]\ttraining's rmse: 5.92895\tvalid_1's rmse: 6.38833\n",
      "[600]\ttraining's rmse: 5.8686\tvalid_1's rmse: 6.36837\n",
      "[650]\ttraining's rmse: 5.81047\tvalid_1's rmse: 6.34591\n",
      "[700]\ttraining's rmse: 5.75227\tvalid_1's rmse: 6.32412\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[750]\ttraining's rmse: 5.69784\tvalid_1's rmse: 6.30488\n",
      "[800]\ttraining's rmse: 5.64605\tvalid_1's rmse: 6.28518\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[850]\ttraining's rmse: 5.59516\tvalid_1's rmse: 6.26752\n",
      "[900]\ttraining's rmse: 5.54692\tvalid_1's rmse: 6.25449\n",
      "[950]\ttraining's rmse: 5.4982\tvalid_1's rmse: 6.23939\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\ttraining's rmse: 5.45065\tvalid_1's rmse: 6.22673\n",
      "[1050]\ttraining's rmse: 5.40531\tvalid_1's rmse: 6.21509\n",
      "[1100]\ttraining's rmse: 5.362\tvalid_1's rmse: 6.20084\n",
      "[1150]\ttraining's rmse: 5.31916\tvalid_1's rmse: 6.18811\n",
      "[1200]\ttraining's rmse: 5.27712\tvalid_1's rmse: 6.17367\n",
      "[1250]\ttraining's rmse: 5.23476\tvalid_1's rmse: 6.16403\n",
      "[1300]\ttraining's rmse: 5.19604\tvalid_1's rmse: 6.15623\n",
      "[1350]\ttraining's rmse: 5.15675\tvalid_1's rmse: 6.14368\n",
      "[1400]\ttraining's rmse: 5.11715\tvalid_1's rmse: 6.13603\n",
      "[1450]\ttraining's rmse: 5.08036\tvalid_1's rmse: 6.12882\n",
      "[1500]\ttraining's rmse: 5.04242\tvalid_1's rmse: 6.12276\n",
      "[1550]\ttraining's rmse: 5.00605\tvalid_1's rmse: 6.11494\n",
      "[1600]\ttraining's rmse: 4.97008\tvalid_1's rmse: 6.10857\n",
      "[1650]\ttraining's rmse: 4.93353\tvalid_1's rmse: 6.10008\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1700]\ttraining's rmse: 4.90029\tvalid_1's rmse: 6.09381\n",
      "[1750]\ttraining's rmse: 4.86581\tvalid_1's rmse: 6.08553\n",
      "[1800]\ttraining's rmse: 4.83221\tvalid_1's rmse: 6.07952\n",
      "[1850]\ttraining's rmse: 4.79984\tvalid_1's rmse: 6.07458\n",
      "[1900]\ttraining's rmse: 4.76844\tvalid_1's rmse: 6.07061\n",
      "[1950]\ttraining's rmse: 4.7358\tvalid_1's rmse: 6.06466\n",
      "[2000]\ttraining's rmse: 4.70437\tvalid_1's rmse: 6.06079\n",
      "[2050]\ttraining's rmse: 4.67376\tvalid_1's rmse: 6.05578\n",
      "[2100]\ttraining's rmse: 4.64338\tvalid_1's rmse: 6.04964\n",
      "[2150]\ttraining's rmse: 4.61356\tvalid_1's rmse: 6.04399\n",
      "[2200]\ttraining's rmse: 4.58475\tvalid_1's rmse: 6.04001\n",
      "[2250]\ttraining's rmse: 4.55686\tvalid_1's rmse: 6.03577\n",
      "[2300]\ttraining's rmse: 4.52712\tvalid_1's rmse: 6.02909\n",
      "[2350]\ttraining's rmse: 4.49902\tvalid_1's rmse: 6.02447\n",
      "[2400]\ttraining's rmse: 4.47113\tvalid_1's rmse: 6.01963\n",
      "[2450]\ttraining's rmse: 4.44338\tvalid_1's rmse: 6.01614\n",
      "[2500]\ttraining's rmse: 4.41681\tvalid_1's rmse: 6.01274\n",
      "[2550]\ttraining's rmse: 4.38955\tvalid_1's rmse: 6.00889\n",
      "[2600]\ttraining's rmse: 4.36343\tvalid_1's rmse: 6.00432\n",
      "[2650]\ttraining's rmse: 4.33723\tvalid_1's rmse: 5.99993\n",
      "[2700]\ttraining's rmse: 4.31184\tvalid_1's rmse: 5.99545\n",
      "[2750]\ttraining's rmse: 4.28694\tvalid_1's rmse: 5.99268\n",
      "[2800]\ttraining's rmse: 4.2617\tvalid_1's rmse: 5.98833\n",
      "[2850]\ttraining's rmse: 4.23693\tvalid_1's rmse: 5.98561\n",
      "[2900]\ttraining's rmse: 4.21313\tvalid_1's rmse: 5.98182\n",
      "[2950]\ttraining's rmse: 4.18917\tvalid_1's rmse: 5.97973\n",
      "[3000]\ttraining's rmse: 4.16436\tvalid_1's rmse: 5.97702\n",
      "[3050]\ttraining's rmse: 4.14032\tvalid_1's rmse: 5.97402\n",
      "[3100]\ttraining's rmse: 4.11653\tvalid_1's rmse: 5.97084\n",
      "[3150]\ttraining's rmse: 4.09246\tvalid_1's rmse: 5.96793\n",
      "[3200]\ttraining's rmse: 4.06903\tvalid_1's rmse: 5.96686\n",
      "[3250]\ttraining's rmse: 4.04589\tvalid_1's rmse: 5.96566\n",
      "[3300]\ttraining's rmse: 4.02436\tvalid_1's rmse: 5.96486\n",
      "[3350]\ttraining's rmse: 4.00216\tvalid_1's rmse: 5.96143\n",
      "[3400]\ttraining's rmse: 3.97998\tvalid_1's rmse: 5.95875\n",
      "[3450]\ttraining's rmse: 3.95925\tvalid_1's rmse: 5.95614\n",
      "[3500]\ttraining's rmse: 3.93687\tvalid_1's rmse: 5.95311\n",
      "[3550]\ttraining's rmse: 3.91586\tvalid_1's rmse: 5.94962\n",
      "[3600]\ttraining's rmse: 3.89438\tvalid_1's rmse: 5.94758\n",
      "[3650]\ttraining's rmse: 3.87364\tvalid_1's rmse: 5.94576\n",
      "[3700]\ttraining's rmse: 3.85359\tvalid_1's rmse: 5.94379\n",
      "[3750]\ttraining's rmse: 3.83336\tvalid_1's rmse: 5.94269\n",
      "[3800]\ttraining's rmse: 3.8138\tvalid_1's rmse: 5.94166\n",
      "[3850]\ttraining's rmse: 3.79343\tvalid_1's rmse: 5.94024\n",
      "[3900]\ttraining's rmse: 3.77314\tvalid_1's rmse: 5.93836\n",
      "[3950]\ttraining's rmse: 3.75353\tvalid_1's rmse: 5.93656\n",
      "[4000]\ttraining's rmse: 3.73418\tvalid_1's rmse: 5.93499\n",
      "[4050]\ttraining's rmse: 3.71549\tvalid_1's rmse: 5.9339\n",
      "[4100]\ttraining's rmse: 3.69676\tvalid_1's rmse: 5.93202\n",
      "[4150]\ttraining's rmse: 3.6778\tvalid_1's rmse: 5.93005\n",
      "[4200]\ttraining's rmse: 3.65966\tvalid_1's rmse: 5.92921\n",
      "[4250]\ttraining's rmse: 3.64113\tvalid_1's rmse: 5.92488\n",
      "[4300]\ttraining's rmse: 3.62359\tvalid_1's rmse: 5.92386\n",
      "[4350]\ttraining's rmse: 3.60517\tvalid_1's rmse: 5.92203\n",
      "[4400]\ttraining's rmse: 3.58701\tvalid_1's rmse: 5.92114\n",
      "[4450]\ttraining's rmse: 3.56946\tvalid_1's rmse: 5.91865\n",
      "[4500]\ttraining's rmse: 3.55283\tvalid_1's rmse: 5.91626\n",
      "[4550]\ttraining's rmse: 3.53561\tvalid_1's rmse: 5.91502\n",
      "[4600]\ttraining's rmse: 3.51868\tvalid_1's rmse: 5.9134\n",
      "[4650]\ttraining's rmse: 3.50274\tvalid_1's rmse: 5.91258\n",
      "[4700]\ttraining's rmse: 3.48519\tvalid_1's rmse: 5.9104\n",
      "[4750]\ttraining's rmse: 3.46872\tvalid_1's rmse: 5.90967\n",
      "[4800]\ttraining's rmse: 3.45258\tvalid_1's rmse: 5.90845\n",
      "[4850]\ttraining's rmse: 3.43656\tvalid_1's rmse: 5.90743\n",
      "[4900]\ttraining's rmse: 3.42052\tvalid_1's rmse: 5.90576\n",
      "[4950]\ttraining's rmse: 3.40505\tvalid_1's rmse: 5.90391\n",
      "[5000]\ttraining's rmse: 3.38987\tvalid_1's rmse: 5.90407\n",
      "[5050]\ttraining's rmse: 3.37481\tvalid_1's rmse: 5.90228\n",
      "[5100]\ttraining's rmse: 3.36059\tvalid_1's rmse: 5.90135\n",
      "[5150]\ttraining's rmse: 3.34618\tvalid_1's rmse: 5.89942\n",
      "[5200]\ttraining's rmse: 3.33086\tvalid_1's rmse: 5.89829\n",
      "[5250]\ttraining's rmse: 3.31627\tvalid_1's rmse: 5.89775\n",
      "[5300]\ttraining's rmse: 3.30152\tvalid_1's rmse: 5.89688\n",
      "[5350]\ttraining's rmse: 3.28667\tvalid_1's rmse: 5.89569\n",
      "[5400]\ttraining's rmse: 3.27198\tvalid_1's rmse: 5.89369\n",
      "[5450]\ttraining's rmse: 3.2586\tvalid_1's rmse: 5.89374\n",
      "[5500]\ttraining's rmse: 3.24402\tvalid_1's rmse: 5.8916\n",
      "[5550]\ttraining's rmse: 3.23038\tvalid_1's rmse: 5.8907\n",
      "[5600]\ttraining's rmse: 3.21647\tvalid_1's rmse: 5.88983\n",
      "[5650]\ttraining's rmse: 3.20244\tvalid_1's rmse: 5.88901\n",
      "[5700]\ttraining's rmse: 3.18815\tvalid_1's rmse: 5.88809\n",
      "[5750]\ttraining's rmse: 3.17402\tvalid_1's rmse: 5.8877\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5800]\ttraining's rmse: 3.16072\tvalid_1's rmse: 5.88647\n",
      "[5850]\ttraining's rmse: 3.1477\tvalid_1's rmse: 5.88623\n",
      "[5900]\ttraining's rmse: 3.13464\tvalid_1's rmse: 5.88553\n",
      "[5950]\ttraining's rmse: 3.1219\tvalid_1's rmse: 5.88629\n",
      "[6000]\ttraining's rmse: 3.10936\tvalid_1's rmse: 5.88505\n",
      "[6050]\ttraining's rmse: 3.0963\tvalid_1's rmse: 5.88455\n",
      "[6100]\ttraining's rmse: 3.08369\tvalid_1's rmse: 5.88319\n",
      "[6150]\ttraining's rmse: 3.07097\tvalid_1's rmse: 5.88342\n",
      "[6200]\ttraining's rmse: 3.05865\tvalid_1's rmse: 5.88214\n",
      "[6250]\ttraining's rmse: 3.04695\tvalid_1's rmse: 5.8807\n",
      "[6300]\ttraining's rmse: 3.03476\tvalid_1's rmse: 5.88044\n",
      "[6350]\ttraining's rmse: 3.02294\tvalid_1's rmse: 5.87982\n",
      "[6400]\ttraining's rmse: 3.01105\tvalid_1's rmse: 5.87973\n",
      "[6450]\ttraining's rmse: 3\tvalid_1's rmse: 5.88039\n",
      "[6500]\ttraining's rmse: 2.98819\tvalid_1's rmse: 5.88006\n",
      "[6550]\ttraining's rmse: 2.97657\tvalid_1's rmse: 5.87866\n",
      "[6600]\ttraining's rmse: 2.96498\tvalid_1's rmse: 5.87701\n",
      "[6650]\ttraining's rmse: 2.95358\tvalid_1's rmse: 5.8759\n",
      "[6700]\ttraining's rmse: 2.94207\tvalid_1's rmse: 5.87497\n",
      "[6750]\ttraining's rmse: 2.9309\tvalid_1's rmse: 5.87463\n",
      "[6800]\ttraining's rmse: 2.91984\tvalid_1's rmse: 5.87415\n",
      "[6850]\ttraining's rmse: 2.90878\tvalid_1's rmse: 5.87315\n",
      "[6900]\ttraining's rmse: 2.89814\tvalid_1's rmse: 5.87262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6950]\ttraining's rmse: 2.88673\tvalid_1's rmse: 5.87186\n",
      "[7000]\ttraining's rmse: 2.87594\tvalid_1's rmse: 5.8715\n",
      "[7050]\ttraining's rmse: 2.86492\tvalid_1's rmse: 5.87079\n",
      "[7100]\ttraining's rmse: 2.85507\tvalid_1's rmse: 5.87071\n",
      "[7150]\ttraining's rmse: 2.84462\tvalid_1's rmse: 5.87044\n",
      "[7200]\ttraining's rmse: 2.83424\tvalid_1's rmse: 5.86994\n",
      "[7250]\ttraining's rmse: 2.82359\tvalid_1's rmse: 5.86899\n",
      "[7300]\ttraining's rmse: 2.81351\tvalid_1's rmse: 5.86759\n",
      "[7350]\ttraining's rmse: 2.80328\tvalid_1's rmse: 5.86739\n",
      "[7400]\ttraining's rmse: 2.79306\tvalid_1's rmse: 5.86638\n",
      "[7450]\ttraining's rmse: 2.78327\tvalid_1's rmse: 5.86513\n",
      "[7500]\ttraining's rmse: 2.77377\tvalid_1's rmse: 5.86538\n",
      "[7550]\ttraining's rmse: 2.76394\tvalid_1's rmse: 5.86491\n",
      "[7600]\ttraining's rmse: 2.75467\tvalid_1's rmse: 5.86445\n",
      "[7650]\ttraining's rmse: 2.7449\tvalid_1's rmse: 5.86444\n",
      "[7700]\ttraining's rmse: 2.73509\tvalid_1's rmse: 5.86328\n",
      "[7750]\ttraining's rmse: 2.72567\tvalid_1's rmse: 5.86264\n",
      "[7800]\ttraining's rmse: 2.71616\tvalid_1's rmse: 5.86185\n",
      "[7850]\ttraining's rmse: 2.70723\tvalid_1's rmse: 5.86101\n",
      "[7900]\ttraining's rmse: 2.69799\tvalid_1's rmse: 5.86083\n",
      "[7950]\ttraining's rmse: 2.68901\tvalid_1's rmse: 5.86062\n",
      "[8000]\ttraining's rmse: 2.68008\tvalid_1's rmse: 5.86137\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[8000]\ttraining's rmse: 2.68008\tvalid_1's rmse: 5.86137\n",
      "Train RMSE: 2.680076832846274        Valida RMSE: 5.861367387198663\n",
      "OOF RMSE: 5.903267847092795 \n"
     ]
    }
   ],
   "source": [
    "results,models,importances,oof,feature_list = Training_Lightgbm(df_train[columns_modeling_last],params,fold_column = 'fold',target_column = 'target',cat_vars = cat_columns ,metric = 'RMSE',early_stopping = 200,max_boost_round = 8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6af70676a54b80bc6675b95fff979d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=798.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mode: Missing as new category\n",
      "Applying Label Encoding:  label_states_en_brands\n",
      "Applying Label Encoding:  label_states_en_categories\n",
      "Applying Label Encoding:  label_states_en_characteristics\n",
      "Applying Label Encoding:  label_states_en_expiration date\n",
      "Applying Label Encoding:  label_states_en_general_complete\n",
      "Applying Label Encoding:  label_states_en_ingredients\n",
      "Applying Label Encoding:  label_pnns_groups_1\n",
      "Applying Label Encoding:  label_pnns_groups_2\n",
      "Applying Label Encoding:  label_states_en_packaging\n",
      "Applying Label Encoding:  label_states_en_packaging-code-\n",
      "Applying Label Encoding:  label_states_en_photo_upload\n",
      "Applying Label Encoding:  label_states_en_photo_validate\n",
      "Applying Label Encoding:  label_states_en_product name\n",
      "Applying Label Encoding:  label_states_en_quantity\n"
     ]
    }
   ],
   "source": [
    "df_test      = pd.read_csv(os.path.join(DATA_PATH,'test_preprocessed.csv'))\n",
    "df_test['target'] = -1\n",
    "test_dataset = BNPParibasText(df_test,MAX_LENGTH,tokenizer,COLUMN_NAME)\n",
    "model         = Roberta_Model(pretrained_model=PRETRAINED)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size  = 32,\n",
    "        pin_memory  = True,\n",
    "        num_workers = 72\n",
    "    )\n",
    "emb_sentence_test = get_embedding(test_loader, model, 'cuda')\n",
    "df_test[[f'emb_{i}' for i in range(emb_sentence_train.shape[1])]] = emb_sentence_test\n",
    "df_test = apply_label_encoder(df_test,dict_le,drop_original = True, missing_new_cat = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin_predict\n",
      "fin_predict\n",
      "fin_predict\n",
      "fin_predict\n",
      "fin_predict\n",
      "Real:  5.748087686708285\n"
     ]
    }
   ],
   "source": [
    "probs = 0\n",
    "for i in models:\n",
    "    probs = probs + (i.predict(df_test[feature_list]))\n",
    "    \n",
    "    print('fin_predict')\n",
    "y_test_pred = probs/5.0\n",
    "print(f'Real: ',math.sqrt(mean_squared_error(y_test_pred,df_test['Target'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37320</th>\n",
       "      <td>14.072644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>20.038400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112180</th>\n",
       "      <td>10.424357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128820</th>\n",
       "      <td>12.515797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16037</th>\n",
       "      <td>19.302766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           target\n",
       "Index            \n",
       "37320   14.072644\n",
       "3913    20.038400\n",
       "112180  10.424357\n",
       "128820  12.515797\n",
       "16037   19.302766"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_submission['target'] = y_test_pred\n",
    "y_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests number 1\n",
      "200\n",
      "{'Date': 'Tue, 18 May 2021 20:58:56 GMT', 'Content-Type': 'application/json', 'Content-Length': '495', 'Connection': 'keep-alive', 'X-Request-ID': '9VDYQEXOTIL4RSGH', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'POST', 'Access-Control-Allow-Headers': 'authorization,content-type'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'competition_name': 'food',\n",
       " 'file_path': 'none',\n",
       " 'message': 'Submission validated.',\n",
       " 'name': 'Insight ML - DD',\n",
       " 'result_csv_file': 'test_v2',\n",
       " 'score': 5.748294411988524,\n",
       " 'score2': None,\n",
       " 'score3': None,\n",
       " 'sub_name': 'test_v2',\n",
       " 'sub_uid': '8ff2732f-f618-4572-912d-bfd4d0799d1d',\n",
       " 'submission_time': '2021/05/18, 20:58:56'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Enviar los resultados\n",
    "apiquery.submit_api(y_submission,\n",
    "       competition_name='food',\n",
    "        subname='test_v2', # Pueden cambiar esto sin problemas, poner el nombre que quieran.\n",
    "        holdout_key='None',\n",
    "        update_ldb=True,\n",
    "        username=\"Insight ML - DD\" # Poner el nombre de su equipo como un string. \n",
    "                                  # El mejor de los resultados dentro de sus envios es el que aparecera en la tabla de posiciones.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
